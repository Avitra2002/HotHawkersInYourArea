{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Total records: 54000\n",
      "\n",
      "Dwell Time Statistics by Store:\n",
      "                count       mean       std  min   25%   50%   75%   max\n",
      "store                                                                  \n",
      "Chicken Rice  18000.0  16.879222  6.296768  4.0  12.0  16.0  21.0  43.0\n",
      "Indian        18000.0  15.482444  4.699814  4.0  12.0  15.0  19.0  35.0\n",
      "Taiwanese     18000.0  16.036389  5.339474  4.0  12.0  15.0  19.0  38.0\n",
      "\n",
      "Sample of the data:\n",
      "                      timestamp         store  dwell_time\n",
      "0      2024-12-22T02:00:00.000Z  Chicken Rice           6\n",
      "18000  2024-12-22T02:00:00.000Z        Indian          10\n",
      "36000  2024-12-22T02:00:00.000Z     Taiwanese          11\n",
      "1      2024-12-22T02:01:00.000Z  Chicken Rice          11\n",
      "18001  2024-12-22T02:01:00.000Z        Indian          10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_dwell_time_data(start_date, num_days, noise_level=0.2):\n",
    "    \"\"\"\n",
    "    Generate synthetic canteen dwell time data for multiple stores.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_date: datetime object for the start date\n",
    "    - num_days: number of days to generate data for\n",
    "    - noise_level: amount of random variation (0-1)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with timestamp, store, and dwell_time columns\n",
    "    \"\"\"\n",
    "    # Store types\n",
    "    stores = ['Chicken Rice', 'Indian', 'Taiwanese']\n",
    "    \n",
    "    # Base parameters\n",
    "    hours_per_day = 10  # 10am to 7pm = 10 hours\n",
    "    readings_per_hour = 60  # 1-minute intervals\n",
    "    \n",
    "    # Create timestamp range\n",
    "    timestamps = []\n",
    "    current_date = start_date\n",
    "    for day in range(num_days):\n",
    "        for hour in range(10, 20):  # 10 AM to 7 PM\n",
    "            for minute in range(60):  # 1-minute intervals\n",
    "                timestamps.append(current_date.replace(hour=hour, minute=minute))\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    # Create store-specific patterns\n",
    "    all_data = []\n",
    "    \n",
    "    for store in stores:\n",
    "        # Base dwell time pattern (in minutes)\n",
    "        base_pattern = []\n",
    "        for _ in range(num_days):\n",
    "            daily_pattern = []\n",
    "            for hour in range(10, 20):\n",
    "                # Store-specific patterns\n",
    "                if store == 'Chicken Rice':\n",
    "                    # Highest during lunch\n",
    "                    if 11 <= hour < 14:\n",
    "                        base_time = 25\n",
    "                    else:\n",
    "                        base_time = 15\n",
    "                elif store == 'Indian':\n",
    "                    # More consistent throughout the day\n",
    "                    if 12 <= hour < 15:\n",
    "                        base_time = 20\n",
    "                    else:\n",
    "                        base_time = 15\n",
    "                else:  # Taiwanese\n",
    "                    # Popular during late afternoon\n",
    "                    if 15 <= hour < 18:\n",
    "                        base_time = 22\n",
    "                    else:\n",
    "                        base_time = 15\n",
    "                \n",
    "                # Add the base time for each 1-minute interval\n",
    "                daily_pattern.extend([base_time] * readings_per_hour)\n",
    "            base_pattern.extend(daily_pattern)\n",
    "        \n",
    "        # Add random variation\n",
    "        noise = np.random.normal(0, noise_level * np.mean(base_pattern), len(base_pattern))\n",
    "        dwell_times = np.maximum(5, np.array(base_pattern) + noise)  # Ensure minimum 5 minutes\n",
    "        \n",
    "        # Create store-specific DataFrame\n",
    "        df_store = pd.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'store': store,\n",
    "            'dwell_time': dwell_times\n",
    "        })\n",
    "        \n",
    "        # Add day of week feature for patterns\n",
    "        df_store['day_of_week'] = df_store['timestamp'].dt.day_name()\n",
    "        \n",
    "        # Add weekly patterns\n",
    "        df_store.loc[df_store['day_of_week'].isin(['Saturday', 'Sunday']), 'dwell_time'] *= 0.7  # Lower on weekends\n",
    "        df_store.loc[df_store['day_of_week'] == 'Friday', 'dwell_time'] *= 1.2  # Higher on Fridays\n",
    "        \n",
    "        all_data.append(df_store)\n",
    "    \n",
    "    # Combine all store data\n",
    "    df_final = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Convert timestamps to UTC format\n",
    "    df_final['timestamp'] = df_final['timestamp'].dt.tz_localize('Asia/Singapore').dt.tz_convert('UTC').dt.strftime('%Y-%m-%dT%H:%M:00.000Z')\n",
    "    \n",
    "    # Drop the day_of_week column and round dwell times\n",
    "    df_final = df_final.drop('day_of_week', axis=1)\n",
    "    df_final['dwell_time'] = df_final['dwell_time'].round().astype(int)\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df_final = df_final.sort_values('timestamp')\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Start from current date\n",
    "    start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    num_days = 30  # Generate 30 days of data\n",
    "    \n",
    "    df = generate_dwell_time_data(start_date, num_days)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('synthetic_dwell_times.csv', index=False)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(\"\\nDwell Time Statistics by Store:\")\n",
    "    print(df.groupby('store')['dwell_time'].describe())\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1487 - mae: 0.3261 - val_loss: 0.1410 - val_mae: 0.3229\n",
      "Epoch 2/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3253 - val_loss: 0.1410 - val_mae: 0.3232\n",
      "Epoch 3/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3250 - val_loss: 0.1410 - val_mae: 0.3224\n",
      "Epoch 4/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3246 - val_loss: 0.1409 - val_mae: 0.3223\n",
      "Epoch 5/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.3246 - val_loss: 0.1410 - val_mae: 0.3222\n",
      "Epoch 6/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3246 - val_loss: 0.1409 - val_mae: 0.3218\n",
      "Epoch 7/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3248 - val_loss: 0.1409 - val_mae: 0.3227\n",
      "Epoch 8/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3234\n",
      "Epoch 9/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1415 - mae: 0.3242 - val_loss: 0.1409 - val_mae: 0.3229\n",
      "Epoch 10/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3236\n",
      "Epoch 11/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3223\n",
      "Epoch 12/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3226\n",
      "Epoch 13/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1414 - mae: 0.3241 - val_loss: 0.1409 - val_mae: 0.3229\n",
      "Epoch 14/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1415 - mae: 0.3242 - val_loss: 0.1409 - val_mae: 0.3237\n",
      "Epoch 15/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.3244 - val_loss: 0.1409 - val_mae: 0.3229\n",
      "Epoch 16/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3246 - val_loss: 0.1409 - val_mae: 0.3219\n",
      "Epoch 17/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3228\n",
      "Epoch 18/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1418 - mae: 0.3248 - val_loss: 0.1409 - val_mae: 0.3224\n",
      "Epoch 19/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3246 - val_loss: 0.1409 - val_mae: 0.3227\n",
      "Epoch 20/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.3248 - val_loss: 0.1409 - val_mae: 0.3231\n",
      "Epoch 21/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1409 - val_mae: 0.3226\n",
      "Epoch 22/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1409 - val_mae: 0.3228\n",
      "Epoch 23/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3256 - val_loss: 0.1409 - val_mae: 0.3222\n",
      "Epoch 24/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1415 - mae: 0.3241 - val_loss: 0.1409 - val_mae: 0.3229\n",
      "Epoch 25/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1412 - mae: 0.3237 - val_loss: 0.1409 - val_mae: 0.3236\n",
      "Epoch 26/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1409 - val_mae: 0.3238\n",
      "Epoch 27/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1411 - mae: 0.3234 - val_loss: 0.1409 - val_mae: 0.3225\n",
      "Epoch 28/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1416 - mae: 0.3244 - val_loss: 0.1409 - val_mae: 0.3228\n",
      "Epoch 29/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3232\n",
      "Epoch 30/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1413 - mae: 0.3240 - val_loss: 0.1409 - val_mae: 0.3227\n",
      "Epoch 31/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1412 - mae: 0.3237 - val_loss: 0.1409 - val_mae: 0.3224\n",
      "Epoch 32/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1415 - mae: 0.3240 - val_loss: 0.1408 - val_mae: 0.3229\n",
      "Epoch 33/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1414 - mae: 0.3239 - val_loss: 0.1408 - val_mae: 0.3220\n",
      "Epoch 34/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1414 - mae: 0.3239 - val_loss: 0.1409 - val_mae: 0.3233\n",
      "Epoch 35/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3246 - val_loss: 0.1408 - val_mae: 0.3220\n",
      "Epoch 36/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3251 - val_loss: 0.1409 - val_mae: 0.3228\n",
      "Epoch 37/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3247 - val_loss: 0.1409 - val_mae: 0.3224\n",
      "Epoch 38/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1415 - mae: 0.3242 - val_loss: 0.1408 - val_mae: 0.3229\n",
      "Epoch 39/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3251 - val_loss: 0.1409 - val_mae: 0.3214\n",
      "Epoch 40/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1409 - val_mae: 0.3227\n",
      "Epoch 41/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3245 - val_loss: 0.1408 - val_mae: 0.3226\n",
      "Epoch 42/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1415 - mae: 0.3240 - val_loss: 0.1409 - val_mae: 0.3236\n",
      "Epoch 43/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3244 - val_loss: 0.1409 - val_mae: 0.3226\n",
      "Epoch 44/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1409 - val_mae: 0.3234\n",
      "Epoch 45/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1414 - mae: 0.3242 - val_loss: 0.1409 - val_mae: 0.3223\n",
      "Epoch 46/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3244 - val_loss: 0.1408 - val_mae: 0.3230\n",
      "Epoch 47/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3244 - val_loss: 0.1409 - val_mae: 0.3229\n",
      "Epoch 48/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3243 - val_loss: 0.1409 - val_mae: 0.3236\n",
      "Epoch 49/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3248 - val_loss: 0.1408 - val_mae: 0.3228\n",
      "Epoch 50/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3251 - val_loss: 0.1409 - val_mae: 0.3236\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "Metrics for Chicken Rice:\n",
      "MAE: 4.77 minutes\n",
      "RMSE: 6.10 minutes\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1454 - mae: 0.3273 - val_loss: 0.1417 - val_mae: 0.3221\n",
      "Epoch 2/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1426 - mae: 0.3268 - val_loss: 0.1419 - val_mae: 0.3200\n",
      "Epoch 3/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3267 - val_loss: 0.1417 - val_mae: 0.3218\n",
      "Epoch 4/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3268 - val_loss: 0.1415 - val_mae: 0.3229\n",
      "Epoch 5/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1422 - mae: 0.3269 - val_loss: 0.1415 - val_mae: 0.3233\n",
      "Epoch 6/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3268 - val_loss: 0.1416 - val_mae: 0.3220\n",
      "Epoch 7/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3261 - val_loss: 0.1415 - val_mae: 0.3229\n",
      "Epoch 8/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1420 - mae: 0.3265 - val_loss: 0.1418 - val_mae: 0.3204\n",
      "Epoch 9/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3263 - val_loss: 0.1416 - val_mae: 0.3221\n",
      "Epoch 10/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3263 - val_loss: 0.1415 - val_mae: 0.3242\n",
      "Epoch 11/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3267 - val_loss: 0.1415 - val_mae: 0.3233\n",
      "Epoch 12/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1426 - mae: 0.3274 - val_loss: 0.1417 - val_mae: 0.3217\n",
      "Epoch 13/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1423 - mae: 0.3272 - val_loss: 0.1416 - val_mae: 0.3231\n",
      "Epoch 14/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3269 - val_loss: 0.1415 - val_mae: 0.3232\n",
      "Epoch 15/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3264 - val_loss: 0.1416 - val_mae: 0.3221\n",
      "Epoch 16/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3266 - val_loss: 0.1416 - val_mae: 0.3225\n",
      "Epoch 17/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3267 - val_loss: 0.1415 - val_mae: 0.3233\n",
      "Epoch 18/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3268 - val_loss: 0.1416 - val_mae: 0.3232\n",
      "Epoch 19/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3262 - val_loss: 0.1417 - val_mae: 0.3223\n",
      "Epoch 20/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3258 - val_loss: 0.1417 - val_mae: 0.3223\n",
      "Epoch 21/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3263 - val_loss: 0.1417 - val_mae: 0.3220\n",
      "Epoch 22/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3263 - val_loss: 0.1416 - val_mae: 0.3231\n",
      "Epoch 23/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1420 - mae: 0.3264 - val_loss: 0.1417 - val_mae: 0.3221\n",
      "Epoch 24/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3264 - val_loss: 0.1416 - val_mae: 0.3229\n",
      "Epoch 25/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3266 - val_loss: 0.1416 - val_mae: 0.3235\n",
      "Epoch 26/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3260 - val_loss: 0.1417 - val_mae: 0.3220\n",
      "Epoch 27/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3262 - val_loss: 0.1415 - val_mae: 0.3236\n",
      "Epoch 28/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3264 - val_loss: 0.1416 - val_mae: 0.3235\n",
      "Epoch 29/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3265 - val_loss: 0.1415 - val_mae: 0.3232\n",
      "Epoch 30/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1421 - mae: 0.3268 - val_loss: 0.1416 - val_mae: 0.3228\n",
      "Epoch 31/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.3258 - val_loss: 0.1416 - val_mae: 0.3229\n",
      "Epoch 32/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3275 - val_loss: 0.1415 - val_mae: 0.3233\n",
      "Epoch 33/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3259 - val_loss: 0.1416 - val_mae: 0.3226\n",
      "Epoch 34/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3257 - val_loss: 0.1416 - val_mae: 0.3232\n",
      "Epoch 35/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3261 - val_loss: 0.1417 - val_mae: 0.3226\n",
      "Epoch 36/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3259 - val_loss: 0.1417 - val_mae: 0.3221\n",
      "Epoch 37/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3261 - val_loss: 0.1416 - val_mae: 0.3230\n",
      "Epoch 38/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3265 - val_loss: 0.1417 - val_mae: 0.3228\n",
      "Epoch 39/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3258 - val_loss: 0.1416 - val_mae: 0.3232\n",
      "Epoch 40/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3269 - val_loss: 0.1417 - val_mae: 0.3227\n",
      "Epoch 41/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3259 - val_loss: 0.1416 - val_mae: 0.3228\n",
      "Epoch 42/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3260 - val_loss: 0.1415 - val_mae: 0.3234\n",
      "Epoch 43/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3267 - val_loss: 0.1416 - val_mae: 0.3232\n",
      "Epoch 44/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3256 - val_loss: 0.1416 - val_mae: 0.3231\n",
      "Epoch 45/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1416 - val_mae: 0.3234\n",
      "Epoch 46/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3275 - val_loss: 0.1415 - val_mae: 0.3229\n",
      "Epoch 47/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1416 - val_mae: 0.3226\n",
      "Epoch 48/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1416 - mae: 0.3258 - val_loss: 0.1417 - val_mae: 0.3226\n",
      "Epoch 49/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3256 - val_loss: 0.1415 - val_mae: 0.3239\n",
      "Epoch 50/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3271 - val_loss: 0.1416 - val_mae: 0.3233\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "Metrics for Indian:\n",
      "MAE: 4.22 minutes\n",
      "RMSE: 5.40 minutes\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1489 - mae: 0.3276 - val_loss: 0.1422 - val_mae: 0.3226\n",
      "Epoch 2/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1434 - mae: 0.3281 - val_loss: 0.1422 - val_mae: 0.3229\n",
      "Epoch 3/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3263 - val_loss: 0.1421 - val_mae: 0.3252\n",
      "Epoch 4/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3268 - val_loss: 0.1421 - val_mae: 0.3234\n",
      "Epoch 5/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1420 - val_mae: 0.3251\n",
      "Epoch 6/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3268 - val_loss: 0.1421 - val_mae: 0.3245\n",
      "Epoch 7/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3268 - val_loss: 0.1420 - val_mae: 0.3244\n",
      "Epoch 8/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3265 - val_loss: 0.1421 - val_mae: 0.3243\n",
      "Epoch 9/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1422 - mae: 0.3266 - val_loss: 0.1420 - val_mae: 0.3243\n",
      "Epoch 10/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3262 - val_loss: 0.1421 - val_mae: 0.3238\n",
      "Epoch 11/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3270 - val_loss: 0.1421 - val_mae: 0.3236\n",
      "Epoch 12/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1421 - val_mae: 0.3233\n",
      "Epoch 13/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3271 - val_loss: 0.1420 - val_mae: 0.3252\n",
      "Epoch 14/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3258 - val_loss: 0.1420 - val_mae: 0.3240\n",
      "Epoch 15/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3271 - val_loss: 0.1421 - val_mae: 0.3259\n",
      "Epoch 16/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3265 - val_loss: 0.1421 - val_mae: 0.3245\n",
      "Epoch 17/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3264 - val_loss: 0.1421 - val_mae: 0.3248\n",
      "Epoch 18/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3267 - val_loss: 0.1421 - val_mae: 0.3243\n",
      "Epoch 19/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1424 - mae: 0.3271 - val_loss: 0.1421 - val_mae: 0.3246\n",
      "Epoch 20/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3273 - val_loss: 0.1421 - val_mae: 0.3240\n",
      "Epoch 21/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1420 - val_mae: 0.3255\n",
      "Epoch 22/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3262 - val_loss: 0.1420 - val_mae: 0.3253\n",
      "Epoch 23/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3272 - val_loss: 0.1421 - val_mae: 0.3242\n",
      "Epoch 24/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3270 - val_loss: 0.1421 - val_mae: 0.3246\n",
      "Epoch 25/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3262 - val_loss: 0.1421 - val_mae: 0.3251\n",
      "Epoch 26/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3266 - val_loss: 0.1422 - val_mae: 0.3240\n",
      "Epoch 27/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3266 - val_loss: 0.1421 - val_mae: 0.3254\n",
      "Epoch 28/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3270 - val_loss: 0.1421 - val_mae: 0.3254\n",
      "Epoch 29/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3262 - val_loss: 0.1421 - val_mae: 0.3245\n",
      "Epoch 30/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3263 - val_loss: 0.1421 - val_mae: 0.3247\n",
      "Epoch 31/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1421 - mae: 0.3267 - val_loss: 0.1421 - val_mae: 0.3247\n",
      "Epoch 32/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3261 - val_loss: 0.1421 - val_mae: 0.3247\n",
      "Epoch 33/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3267 - val_loss: 0.1420 - val_mae: 0.3256\n",
      "Epoch 34/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3272 - val_loss: 0.1421 - val_mae: 0.3245\n",
      "Epoch 35/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3266 - val_loss: 0.1420 - val_mae: 0.3251\n",
      "Epoch 36/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3273 - val_loss: 0.1421 - val_mae: 0.3257\n",
      "Epoch 37/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3273 - val_loss: 0.1420 - val_mae: 0.3253\n",
      "Epoch 38/50\n",
      "\u001b[1m337/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3274"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores:\n\u001b[0;32m--> 126\u001b[0m     predictions, actuals, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     results[store] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions,\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactuals\u001b[39m\u001b[38;5;124m'\u001b[39m: actuals,\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: history\n\u001b[1;32m    131\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[13], line 84\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[0;34m(df, store_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Build and train model\u001b[39;00m\n\u001b[1;32m     82\u001b[0m model \u001b[38;5;241m=\u001b[39m build_lstm_model(input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m---> 84\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     93\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"Create sequences for LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_lstm_data(df, store_name, seq_length=30):\n",
    "    \"\"\"Prepare data for LSTM model\"\"\"\n",
    "    # Filter store data\n",
    "    store_data = df[df['store'] == store_name].copy()\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    store_data['timestamp'] = pd.to_datetime(store_data['timestamp'])\n",
    "    \n",
    "    # Create time features\n",
    "    store_data['hour'] = store_data['timestamp'].dt.hour\n",
    "    store_data['minute'] = store_data['timestamp'].dt.minute\n",
    "    store_data['day_of_week'] = store_data['timestamp'].dt.dayofweek\n",
    "    \n",
    "    # Create cyclical time features\n",
    "    store_data['hour_sin'] = np.sin(2 * np.pi * store_data['hour']/24)\n",
    "    store_data['hour_cos'] = np.cos(2 * np.pi * store_data['hour']/24)\n",
    "    store_data['minute_sin'] = np.sin(2 * np.pi * store_data['minute']/60)\n",
    "    store_data['minute_cos'] = np.cos(2 * np.pi * store_data['minute']/60)\n",
    "    \n",
    "    # One-hot encode day of week\n",
    "    dow_dummies = pd.get_dummies(store_data['day_of_week'], prefix='dow')\n",
    "    store_data = pd.concat([store_data, dow_dummies], axis=1)\n",
    "    \n",
    "    # Select features\n",
    "    feature_columns = ['dwell_time', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos'] + \\\n",
    "                     [col for col in store_data.columns if col.startswith('dow_')]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(store_data[feature_columns])\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(scaled_data, seq_length)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test), scaler\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"Build LSTM model\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_predict(df, store_name):\n",
    "    \"\"\"Train LSTM model and make predictions\"\"\"\n",
    "    # Prepare data\n",
    "    (X_train, y_train), (X_test, y_test), scaler = prepare_lstm_data(df, store_name)\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform predictions to original scale\n",
    "    # Create dummy array with same shape as feature set\n",
    "    dummy = np.zeros((len(predictions), scaler.scale_.shape[0]))\n",
    "    dummy[:, 0] = predictions.flatten()\n",
    "    predictions_unscaled = scaler.inverse_transform(dummy)[:, 0]\n",
    "    \n",
    "    # Inverse transform actual values\n",
    "    dummy = np.zeros((len(y_test), scaler.scale_.shape[0]))\n",
    "    dummy[:, 0] = y_test[:, 0]\n",
    "    actual_unscaled = scaler.inverse_transform(dummy)[:, 0]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions_unscaled - actual_unscaled))\n",
    "    rmse = np.sqrt(np.mean((predictions_unscaled - actual_unscaled)**2))\n",
    "    \n",
    "    print(f\"\\nMetrics for {store_name}:\")\n",
    "    print(f\"MAE: {mae:.2f} minutes\")\n",
    "    print(f\"RMSE: {rmse:.2f} minutes\")\n",
    "    \n",
    "    return predictions_unscaled, actual_unscaled, history\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Read data\n",
    "    df = pd.read_csv('synthetic_dwell_times.csv')\n",
    "    \n",
    "    # Train and predict for each store\n",
    "    stores = ['Chicken Rice', 'Indian', 'Taiwanese']\n",
    "    results = {}\n",
    "    \n",
    "    for store in stores:\n",
    "        predictions, actuals, history = train_and_predict(df, store)\n",
    "        results[store] = {\n",
    "            'predictions': predictions,\n",
    "            'actuals': actuals,\n",
    "            'history': history\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Chicken Rice...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1503 - mae: 0.3248 - val_loss: 0.1413 - val_mae: 0.3188\n",
      "Epoch 2/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3250 - val_loss: 0.1410 - val_mae: 0.3212\n",
      "Epoch 3/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3247 - val_loss: 0.1412 - val_mae: 0.3198\n",
      "Epoch 4/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3249 - val_loss: 0.1410 - val_mae: 0.3219\n",
      "Epoch 5/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3248 - val_loss: 0.1411 - val_mae: 0.3201\n",
      "Epoch 6/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1419 - mae: 0.3251 - val_loss: 0.1410 - val_mae: 0.3209\n",
      "Epoch 7/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3253 - val_loss: 0.1409 - val_mae: 0.3211\n",
      "Epoch 8/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1416 - mae: 0.3245 - val_loss: 0.1409 - val_mae: 0.3224\n",
      "Epoch 9/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3247 - val_loss: 0.1410 - val_mae: 0.3211\n",
      "Epoch 10/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1413 - mae: 0.3239 - val_loss: 0.1410 - val_mae: 0.3220\n",
      "\n",
      "Training model for Indian...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1495 - mae: 0.3282 - val_loss: 0.1415 - val_mae: 0.3257\n",
      "Epoch 2/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3265 - val_loss: 0.1415 - val_mae: 0.3241\n",
      "Epoch 3/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3271 - val_loss: 0.1414 - val_mae: 0.3244\n",
      "Epoch 4/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3268 - val_loss: 0.1414 - val_mae: 0.3254\n",
      "Epoch 5/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1418 - mae: 0.3260 - val_loss: 0.1414 - val_mae: 0.3252\n",
      "Epoch 6/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1421 - mae: 0.3265 - val_loss: 0.1414 - val_mae: 0.3255\n",
      "Epoch 7/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1417 - mae: 0.3260 - val_loss: 0.1415 - val_mae: 0.3233\n",
      "Epoch 8/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1423 - mae: 0.3271 - val_loss: 0.1414 - val_mae: 0.3238\n",
      "Epoch 9/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3273 - val_loss: 0.1415 - val_mae: 0.3236\n",
      "Epoch 10/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.3269 - val_loss: 0.1414 - val_mae: 0.3254\n",
      "\n",
      "Training model for Taiwanese...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phonavitra/Desktop/WTH2024/HotHawkersInYourArea/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1487 - mae: 0.3281 - val_loss: 0.1421 - val_mae: 0.3241\n",
      "Epoch 2/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3267 - val_loss: 0.1420 - val_mae: 0.3245\n",
      "Epoch 3/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1427 - mae: 0.3272 - val_loss: 0.1420 - val_mae: 0.3258\n",
      "Epoch 4/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1423 - mae: 0.3269 - val_loss: 0.1420 - val_mae: 0.3262\n",
      "Epoch 5/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1426 - mae: 0.3273 - val_loss: 0.1420 - val_mae: 0.3253\n",
      "Epoch 6/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1428 - mae: 0.3278 - val_loss: 0.1419 - val_mae: 0.3266\n",
      "Epoch 7/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3271 - val_loss: 0.1420 - val_mae: 0.3249\n",
      "Epoch 8/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1423 - mae: 0.3267 - val_loss: 0.1419 - val_mae: 0.3259\n",
      "Epoch 9/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.3263 - val_loss: 0.1420 - val_mae: 0.3258\n",
      "Epoch 10/10\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1425 - mae: 0.3273 - val_loss: 0.1419 - val_mae: 0.3261\n",
      "Models saved to saved_models\n",
      "Loaded models for stores: ['Chicken Rice', 'Indian', 'Taiwanese']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAoFxJREFUeJzs3XlYlOXixvH7HfZdZVdRUVFUzDUtzbQkRbPllKdNzWz1tGnaYnuWbadNW235lZZtp9TqlLtZapob7img4IYi4Ma+zvv7g+CEQDIKDAPfz3VxjTwz8849+EJy9zzPa5imaQoAAAAAAACoQxZ7BwAAAAAAAEDjQykFAAAAAACAOkcpBQAAAAAAgDpHKQUAAAAAAIA6RykFAAAAAACAOkcpBQAAAAAAgDpHKQUAAAAAAIA6RykFAAAAAACAOkcpBQAAAAAAgDpHKQUAQD3Wpk0b3XLLLWWf//LLLzIMQ7/88ovdMp3u9IyOorKv5S233KI2bdrU2GsYhqFnnnmmxo5XF4qKivTwww8rLCxMFotFV199tb0jlZk1a5YMw9DGjRvP+NhBgwZp0KBBNh1/3759MgxDr7766lkmtJ/6+LMBAIAzoZQCAKAKpb8Al364u7urQ4cOuvfee3X06FF7x7PJggUL7F6O/PVr6ezsrGbNmqlXr16aMGGC/vjjD7tmq67Tz4mqPmqy2KprH3/8sV555RWNHDlSs2fP1gMPPFAnrzt//nwNGzZMAQEBcnV1VfPmzXXdddfp559/rpPXr4/atGlT7rzy8vJSnz599Omnn9o7GgAANcLZ3gEAAKjvnn32WYWHhysvL0+rV6/We++9pwULFmjHjh3y9PSs0ywXX3yxcnNz5erqatPzFixYoHfeecfuxdRll12mm2++WaZp6tSpU9q6datmz56td999Vy+//LImTZpk13xncvHFF+uzzz4rN3b77berT58+uvPOO8vGvL29JUm5ublydnasf279/PPPatGihd544406eT3TNHXrrbdq1qxZ6tGjhyZNmqSQkBAdOXJE8+fP1+DBg/Xbb7+pX79+Nh13yZIltZS4bnXv3l2TJ0+WJB05ckQfffSRxo4dq/z8fN1xxx1ljzvbnw0AANiTY/0rCQAAOxg2bJh69+4tqaSA8Pf31+uvv67vv/9eN954Y6XPyc7OlpeXV41nsVgscnd3r/Hj1pUOHTpo9OjR5cZeeuklXXHFFZo8ebIiIyM1fPhwO6U7s7Zt26pt27blxsaPH6+2bdtWeF+SHPLvKjU1VU2aNKmx41mtVhUUFFT5tXjttdc0a9YsTZw4Ua+//roMwyi77/HHH9dnn312VsVeQylnWrRoUe7cuuWWW9S2bVu98cYb5UopR//ZAABonFi+BwCAjS699FJJUlJSkqSSXxK9vb21d+9eDR8+XD4+Pho1apSkkl/Ip0+fri5dusjd3V3BwcG66667dOLEiXLHNE1T06ZNU8uWLeXp6alLLrlEO3furPDaVe0bs27dOg0fPlxNmzaVl5eXzjvvPM2YMaMs3zvvvCOp/BK6UjWd0Vb+/v766quv5OzsrOeff77stQICAsrNnLJarWrSpImcnJx08uTJsvGXX35Zzs7OysrKKhvbvXu3Ro4cqWbNmsnd3V29e/fWDz/8cM5ZbXX6nlLPPPOMDMNQfHy8Ro8eLT8/PwUGBurJJ5+UaZo6ePCgrrrqKvn6+iokJESvvfZahWPm5+fr6aefVvv27eXm5qawsDA9/PDDys/PL/e4pUuX6qKLLlKTJk3k7e2tjh076rHHHqsya+l+SitWrNDOnTvLzpPScy07O1uTJ09WWFiY3Nzc1LFjR7366qsyTbPCe7733nv1+eefq0uXLnJzc9OiRYsqfc3c3Fy9+OKLioyM1KuvvlruvCw1ZswY9enTp8LXYNKkSQoMDJSXl5f+8Y9/KC0trdxjKttTKi8vT88884w6dOggd3d3hYaG6pprrtHevXur/LqYpqk777xTrq6umjdvXtn4nDlz1KtXL3l4eKhZs2a64YYbdPDgwQoZoqKi9Mcff+iSSy6Rp6enWrRooX//+99Vvt6ZBAYGKjIyskLms/nZUKq+fL8AABofZkoBAGCj0l8G/f39y8aKioo0dOhQXXTRRXr11VfLlvXdddddmjVrlsaNG6f7779fSUlJevvtt7V582b99ttvcnFxkSQ99dRTmjZtmoYPH67hw4crNjZWQ4YMUUFBwRnzLF26VCNGjFBoaKgmTJigkJAQ7dq1Sz/++KMmTJigu+66S4cPH9bSpUsrLD2rq4xn0qpVKw0cOFArVqxQRkaGfH191b9/f61cubLsMdu2bdOpU6dksVj022+/6fLLL5ckrVq1Sj169ChbMrdz5071799fLVq00JQpU+Tl5aX//Oc/uvrqqzV37lz94x//OOe85+r6669Xp06d9NJLL+mnn37StGnT1KxZM73//vu69NJL9fLLL+vzzz/Xgw8+qPPPP18XX3yxpJJi7sorr9Tq1at15513qlOnTtq+fbveeOMNxcfH67vvvpNU8jUYMWKEzjvvPD377LNyc3PTnj179Ntvv1WZKTAwUJ999pmef/55ZWVl6cUXX5QkderUSaZp6sorr9SKFSt02223qXv37lq8eLEeeughJScnV1jq9/PPP+s///mP7r33XgUEBFS5x9bq1at1/PhxTZw4UU5OTtX++t13331q2rSpnn76ae3bt0/Tp0/Xvffeq6+//rrK5xQXF2vEiBFavny5brjhBk2YMEGZmZlaunSpduzYoXbt2lX6nFtvvVVff/215s+fX3bOPf/883ryySd13XXX6fbbb1daWpreeustXXzxxdq8eXO5mWYnTpxQTEyMrrnmGl133XX69ttv9cgjj6hr164aNmxYtd9zqaKiIh06dEhNmzY942PP9LNBcozvFwBAA2YCAIBKffLJJ6Ykc9myZWZaWpp58OBB86uvvjL9/f1NDw8P89ChQ6ZpmubYsWNNSeaUKVPKPX/VqlWmJPPzzz8vN75o0aJy46mpqaarq6t5+eWXm1artexxjz32mCnJHDt2bNnYihUrTEnmihUrTNM0zaKiIjM8PNxs3bq1eeLEiXKv89dj3XPPPWZl/9mvjYxVkWTec889Vd4/YcIEU5K5detW0zRN85VXXjGdnJzMjIwM0zRN88033zRbt25t9unTx3zkkUdM0zTN4uJis0mTJuYDDzxQdpzBgwebXbt2NfPy8sp9Lfr162dGRESUjZ3+tTTNkr/L1q1bn/G9/JWXl1eV71+S+fTTT5d9/vTTT5uSzDvvvLNsrKioyGzZsqVpGIb50ksvlY2fOHHC9PDwKHfszz77zLRYLOaqVavKvc7MmTNNSeZvv/1mmqZpvvHGG6YkMy0tzab3YpqmOXDgQLNLly7lxr777jtTkjlt2rRy4yNHjjQNwzD37NlT7j1bLBZz586dZ3ytGTNmmJLM+fPnVytb6fdkdHR0ufPwgQceMJ2cnMyTJ0+Wex8DBw4s+/zjjz82JZmvv/56heOWHispKcmUZL7yyitmYWGhef3115seHh7m4sWLyx67b98+08nJyXz++efLHWP79u2ms7NzufGBAweaksxPP/20bCw/P98MCQkxr7322jO+39atW5tDhgwx09LSzLS0NHP79u3mmDFjKv1eOtufDdX9fgEAoDawfA8AgDOIjo5WYGCgwsLCdMMNN8jb21vz589XixYtyj3uX//6V7nPv/nmG/n5+emyyy5Tenp62UevXr3k7e2tFStWSJKWLVumgoIC3XfffeWWL02cOPGM2TZv3qykpCRNnDixwj5AlS2FOl1dZKyu0plOmZmZkqQBAwaouLhYa9askVQyI2rAgAEaMGCAVq1aJUnasWOHTp48qQEDBkiSjh8/rp9//lnXXXedMjMzy97PsWPHNHToUCUkJCg5ObnGMp+t22+/vezPTk5O6t27t0zT1G233VY23qRJE3Xs2FGJiYllY9988406deqkyMjIcn9fpUtKS/++Ss+F77//Xlar9ZzzLliwQE5OTrr//vvLjU+ePFmmaWrhwoXlxgcOHKjOnTuf8bgZGRmSJB8fH5vy3HnnneXOw9JzZf/+/VU+Z+7cuQoICNB9991X4b7Tv1cKCgr0z3/+Uz/++KMWLFigIUOGlN03b948Wa1WXXfddeX+DkJCQhQREVH2d1DK29u73J5Qrq6u6tOnT7m/17+zZMkSBQYGKjAwUF27dtVnn32mcePG6ZVXXvnb51XnZ4OjfL8AABoulu8BAHAG77zzjjp06CBnZ2cFBwerY8eOsljK/38dZ2dntWzZstxYQkKCTp06paCgoEqPm5qaKkllv0hHRESUuz8wMPCMS3RKlxJGRUVV/w3VccbqKt0TqrSg6Nmzpzw9PbVq1SoNHTpUq1at0tSpUxUSEqK33npLeXl5ZeXURRddJEnas2ePTNPUk08+qSeffLLK93R6oVjXWrVqVe5zPz8/ubu7KyAgoML4sWPHyj5PSEjQrl27FBgYWOlxS/++rr/+en300Ue6/fbbNWXKFA0ePFjXXHONRo4cWeHcrY79+/erefPmFcqjTp06ld3/V+Hh4dU6rq+vr6T/FZHVdfrXr/QcPH0ftL/au3evOnbsWK1N01988UVlZWVp4cKFFfalSkhIkGmaFb4XSpUudy3VsmXLCqVX06ZNtW3btjPmkKS+fftq2rRpKi4u1o4dOzRt2jSdOHHijBu5V+dng6N8vwAAGi5KKQAAzqBPnz5lV9+ripubW4Vf9q1Wq4KCgvT5559X+pyqioW6VJ8y7tixQ05OTmWFhouLi/r27auVK1dqz549SklJ0YABAxQcHKzCwkKtW7dOq1atUmRkZFnO0llBDz74oIYOHVrp67Rv375u3tDfqGz/pKr2VDL/spG41WpV165d9frrr1f62LCwMEmSh4eHVq5cqRUrVuinn37SokWL9PXXX+vSSy/VkiVLbNq/6Wx4eHhU63GRkZGSpO3bt+vqq6+u9vGr87U6F0OHDtWiRYv073//W4MGDSp3VTur1SrDMLRw4cJKc5TO+KuprAEBAYqOji7LFRkZqREjRmjGjBnlLgRwNhzl+wUA0HBRSgEAUEvatWunZcuWqX///n/7S3rr1q0llczAaNu2bdl4Wlra3878KH0NqaTQKf3FtTJVLeWri4zVceDAAf3666+68MILy83GGTBggF5++WUtW7ZMAQEBioyMlGEY6tKli1atWqVVq1ZpxIgRZY8vzebi4vK3Xw9H1a5dO23dulWDBw8+4/JMi8WiwYMHa/DgwXr99df1wgsv6PHHH9eKFSts/tq0bt1ay5YtU2ZmZrm/n927d5fdfzYuuugiNW3aVF9++aUee+yxWi3L2rVrp3Xr1qmwsLDCbKbTXXDBBRo/frxGjBihf/7zn5o/f37ZDKt27drJNE2Fh4erQ4cOtZa3KpdffrkGDhyoF154QXfddZe8vLwqfVx1fjY09O8XAED9x55SAADUkuuuu07FxcV67rnnKtxXVFSkkydPSirZs8rFxUVvvfVWudkT06dPP+Nr9OzZU+Hh4Zo+fXrZ8Ur99Vilv7ie/pi6yHgmx48f14033qji4mI9/vjj5e4bMGCA8vPzNX36dF100UVlRcyAAQP02Wef6fDhw2X7SUlSUFCQBg0apPfff19Hjhyp8FppaWnnnNeerrvuOiUnJ+vDDz+scF9ubq6ys7MllXxNT9e9e3dJUn5+vs2vO3z4cBUXF+vtt98uN/7GG2/IMIyzuoqcJHl6euqRRx7Rrl279Mgjj1Q6e2jOnDlav379WR3/r6699lqlp6dXeA9S5bOWoqOj9dVXX2nRokUaM2ZM2ayia665Rk5OTpo6dWqF55mmWW65ZW155JFHdOzYsUrPg1LV+dnQ0L9fAAD1HzOlAACoJQMHDtRdd92lF198UVu2bNGQIUPk4uKihIQEffPNN5oxY4ZGjhypwMBAPfjgg3rxxRc1YsQIDR8+XJs3b9bChQsr7DF0OovFovfee09XXHGFunfvrnHjxik0NFS7d+/Wzp07tXjxYklSr169JEn333+/hg4dKicnJ91www11kvGv4uPjNWfOHJmmqYyMDG3dulXffPONsrKy9PrrrysmJqbc4y+88EI5OzsrLi5Od955Z9n4xRdfrPfee0+SypVSUskeYBdddJG6du2qO+64Q23bttXRo0e1du1aHTp0SFu3bq123vpmzJgx+s9//qPx48drxYoV6t+/v4qLi7V792795z//0eLFi9W7d289++yzWrlypS6//HK1bt1aqampevfdd9WyZcuy/bdsccUVV+iSSy7R448/rn379qlbt25asmSJvv/+e02cOLFsVs7ZeOihh7Rz50699tprWrFihUaOHKmQkBClpKTou+++0/r168s2uz8XN998sz799FNNmjRJ69ev14ABA5Sdna1ly5bp7rvv1lVXXVXhOVdffbU++eQT3XzzzfL19dX777+vdu3aadq0aXr00Ue1b98+XX311fLx8VFSUpLmz5+vO++8Uw8++OA55/07w4YNU1RUlF5//XXdc889lc78qu7Phob8/QIAqP8opQAAqEUzZ85Ur1699P777+uxxx6Ts7Oz2rRpo9GjR6t///5lj5s2bZrc3d01c+ZMrVixQn379tWSJUt0+eWXn/E1hg4dqhUrVmjq1Kl67bXXZLVa1a5dO91xxx1lj7nmmmt033336auvviorhW644YY6y1hq6dKlWrp0qSwWi3x9fRUeHq6xY8fqzjvvrPRqbV5eXurRo4c2bNhQrkwpLaLCwsIqLB3r3LmzNm7cqKlTp2rWrFk6duyYgoKC1KNHDz311FPVzlofWSwWfffdd3rjjTf06aefav78+fL09FTbtm01YcKEsuVkV155pfbt26ePP/5Y6enpCggI0MCBAzV16lT5+fmd1ev+8MMPeuqpp/T111/rk08+UZs2bfTKK69o8uTJ5/yePv30U1111VX64IMP9OqrryojI0OBgYG6+OKL9e9//1sXXnjhOb2GVLK304IFC/T888/riy++0Ny5c+Xv719WyFRl9OjRyszM1N133y1fX1+98sormjJlijp06KA33nhDU6dOlVRyLg4ZMkRXXnnlOWetjgcffFC33HKLPv/8c91yyy2VPqY6Pxsa8vcLAKD+M8ya2hESAAAAAAAAqCb2lAIAAAAAAECdo5QCAAAAAABAnaOUAgAAAAAAQJ2jlAIAAAAAAECdo5QCAAAAAABAnaOUAgAAAAAAQJ1ztneA2ma1WnX48GH5+PjIMAx7xwEAAAAAAGjQTNNUZmammjdvLoul6vlQDb6UOnz4sMLCwuwdAwAAAAAAoFE5ePCgWrZsWeX9Db6U8vHxkVTyhfD19bVzmnNTWFioJUuWaMiQIXJxcbF3HOCMOGfhaDhn4Wg4Z+FoOGfhaDhn4WjqyzmbkZGhsLCwsk6mKg2+lCpdsufr69sgSilPT0/5+vryAxEOgXMWjoZzFo6GcxaOhnMWjoZzFo6mvp2zZ9pGiY3OAQAAAAAAUOcopQAAAAAAAFDnKKUAAAAAAABQ5yilAAAAAAAAUOcopQAAAAAAAFDnKKUAAAAAAABQ5yilAAAAAAAAUOcopQAAAAAAAFDnKKUAAAAAAABQ5yilAAAAAAAAUOcopQAAAAAAAFDnKKUAAAAAAABQ5+xaSq1cuVJXXHGFmjdvLsMw9N1331X52PHjx8swDE2fPr3O8gEAAAAAAKB22LWUys7OVrdu3fTOO+/87ePmz5+v33//Xc2bN6+jZAAAAAAAAKhNzvZ88WHDhmnYsGF/+5jk5GTdd999Wrx4sS6//PI6SgYAAAAAAIDaZNdS6kysVqvGjBmjhx56SF26dKnWc/Lz85Wfn1/2eUZGhiSpsLBQhYWFtZKzLizeeVRv/rxHiWlOemfvb7r/0vYa2iXY3rGAv1X6PefI33toXDhn4Wg4Z+FoOGfhaDhn4Wjqyzlb3dev16XUyy+/LGdnZ91///3Vfs6LL76oqVOnVhhfsmSJPD09azJendl6zNDH8U6STEmG4lOzdO9XW3Vrh2J18zftHQ84o6VLl9o7AmATzlk4Gs5ZOBrOWTgazlk4Gnufszk5OdV6XL0tpTZt2qQZM2YoNjZWhmFU+3mPPvqoJk2aVPZ5RkaGwsLCNGTIEPn6+tZG1Fr37ttrZChLpkq/DoYMQ1qT4adHx/Szazbg7xQWFmrp0qW67LLL5OLiYu84wBlxzsLRcM7C0XDOwtFwzsLR1JdztnTV2pnU21Jq1apVSk1NVatWrcrGiouLNXnyZE2fPl379u2r9Hlubm5yc3OrMO7i4uKwP0T2HcvR6fOhTFNKSs9x2PeExsWRv//QOHHOwtFwzsLRcM7C0XDOwtHY+5yt7mvX21JqzJgxio6OLjc2dOhQjRkzRuPGjbNTKvsID/BSXEpmhWIqPMDLLnkAAAAAAADOlV1LqaysLO3Zs6fs86SkJG3ZskXNmjVTq1at5O/vX+7xLi4uCgkJUceOHes6ql1NjI7Q+DmxMoySGVKlDEPKyi+St1u97RYBAAAAAAAqZbHni2/cuFE9evRQjx49JEmTJk1Sjx499NRTT9kzVr0TExWqmaN7qmOwt5wNU2FNPeTqZNGuI5m68YPflZ6Vf+aDAAAAAAAA1CN2nWIzaNAgmWb1rx5X1T5SjUFMVKgGdwzQggULNHz4AO1MydatszZoe/IpXfveGn16ax+19mc5HwAAAAAAcAx2nSmFs9c9rInm/qufwpp5aP+xHF373hrtSD5l71gAAAAAAADVQinlwMIDvDT3X/3UOdRX6VkFuv79tVqdkG7vWAAAAAAAAGdEKeXggnzc9fVdF6hfO39lFxRr3Kz1+n5Lsr1jAQAAAAAA/C1KqQbAx91Fn4w7XyPOC1VhsakJX23RR6sS7R0LAAAAAACgSpRSDYSbs5PevKGHxvVvI0ma9tMuvbhgl6zW6m8kDwAAAAAAUFcopRoQi8XQUyM665GYSEnS+ysTNfmbrSostto5GQAAAAAAQHmUUg2MYRj616B2evWf3eRkMTR/c7Jum71R2flF9o4GAAAAAABQhlKqgRrZq6U+GttbHi5OWhmfphs//F3pWfn2jgUAAAAAACBJcrZ3ANSeSzoG6cs7L9CtszZo26FTGjZ9pXw9XHToRK7CA7w0MTpCMVGh9o4JAAAAAAAaIWZKNXDdw5ro2/EXyt/LVWlZBdqblq38IqviUjI1fk6sFu04Yu+IAAAAAACgEaKUagTaBnqrqZdruTFTkmFIM5Yn2CcUAAAAAABo1CilGomDx3MqjJmmlJiWbYc0AAAAAACgsaOUaiTCA7xkVDLe2t+zzrMAAAAAAABQSjUSE6Mjypbsna6gyFrneQAAAAAAQONGKdVIxESFaubonooM8ZGbs0XhAV5yc7Yo/miWpszbJtM07R0RAAAAAAA0Is72DoC6ExMVqpio0LLPf4lL1W2zN2pebLJaNfPUxOgOdkwHAAAAAAAaE2ZKNWKDOgbpuauiJEnTlyXo202H7JwIAAAAAAA0FpRSjdxNfVvpX4PaSZKmzN2m3/ak2zkRAAAAAABoDCiloIeGdNQV3ZqryGpq/JxNij+aae9IAAAAAACggaOUgiwWQ6+MPE/nt2mqzLwijftkg1Iz8+wdCwAAAAAANGCUUpAkubs46YMxvRUe4KXkk7m6bdZG5RQU2TsWAAAAAABooCilUKapl6s+ueV8NfNy1fbkU7r/y80qtpr2jgUAAAAAABogSimU0ybASx/e3FuuzhYt25WqZ/+7U6ZJMQUAAAAAAGoWpRQq6NW6qaZf312SNHvtfn382z675gEAAAAAAA0PpRQqNbxrqB4bHilJmvbTH1q0I8XOiQAAAAAAQENCKYUq3TGgrUZf0EqmKU38erM2Hzhh70gAAAAAAKCBoJRClQzD0DNXdNElHQOVV2jV7bM36sCxHHvHAgAAAAAADQClFP6Ws5NFb9/UU12a++pYdoFumbVeJ3MK7B0LAAAAAAA4OGd7B0D95+XmrI9vOV//eOc3JaZla+TMtXKyGNqXnq3wAC9NjI5QTFSovWMCAAAAAAAHwkwpVEuwr7s+Hne+3J0t2pOapbiUTOUXWRWXkqnxc2K1aMcRe0cEAAAAAAAOhFIK1RYZ4qtAH7dyY6Ykw5BmLE+wTygAAAAAAOCQKKVgk9TM/ApjpiklpmXbIQ0AAAAAAHBUlFKwSXiAl4zTxgxJbQO97BEHAAAAAAA4KEop2GRidETZkr1SpqQhnYPtFQkAAAAAADggSinYJCYqVDNH91RkiI/cnC3ycS+5gONHq5K07dBJ+4YDAAAAAAAOw9neAeB4YqJCFRMVKknKLyrWrbM26Lc9xzTukw369l/9FB7AUj4AAAAAAPD3mCmFc+Lm7KT3x/RWVAtfHcsu0Jj/W6fUjDx7xwIAAAAAAPUcpRTOmbebs2aN66M2/p46dCJXN3+8Xhl5hfaOBQAAAAAA6jFKKdSIAG83fXprXwV4u2l3SqbumL1ReYXF9o4FAAAAAADqKUop1JhW/p6afev58nFz1rqk45rw1WYVW017xwIAAAAAAPUQpRRqVJfmfvrg5t5ydbJo8c6jeuK7HTJNiikAAAAAAFAepRRq3IXt/DXjhu4yDOnL9Qf0xrIEe0cCAAAAAAD1DKUUasWwrqF67qooSdKbyxP02dp99g0EAAAAAADqFUop1JrRF7TWxOgISdJTP+zUT9uO2DkRAAAAAACoLyilUKsmDI7QqL6tZJrSA19v0Zo96faOBAAAAAAA6gFKKdQqwzD07FVRGhYVooJiq+78bJN2JJ+ydywAAAAAAGBnlFKodU4WQ29c310XtG2mrPwi3fLJBu0/lm3vWAAAAAAAwI6c7R0AjYO7i5M+uLm3rn//d+06kqFr31ujJp6uOng8R+EBXpoYHaGYqFB7xwQAAAAAAHWEmVKoM77uLpp96/ny93ZVelaB9qRmKb/IqriUTI2fE6tFO9gIHQAAAACAxoJSCnUqyMddfh4u5cZMSYYhzVieYJ9QAAAAAACgzlFKoc4ln8itMGaaUmIa+0wBAAAAANBYUEqhzoUHeMmoZLxtoFedZwEAAAAAAPZBKYU6NzE6omzJ3l9dHBFolzwAAAAAAKDuUUqhzsVEhWrm6J6KDPGRm7NFTT1L9piavXafth06ad9wAAAAAACgTjjbOwAap5ioUMVEhUqSioqtum32Rv0an6bbZm/U9/f0V/MmHnZOCAAAAAAAahMzpWB3zk4WvX1TD3UM9lFaZr5unbVBWflF9o4FAAAAAABqEaUU6gUfdxf93y29FeDtpt0pmbr/y80qtpr2jgUAAAAAAGoJpRTqjZZNPfXR2N5yc7bo592pmvbTH/aOBAAAAAAAagmlFOqV7mFN9Mb13SVJn/y2T5+u3WfXPAAAAAAAoHZQSqHeGd41VA8N7ShJeuaHnfolLtXOiQAAAAAAQE2jlEK9dPegdhrZq6WspnTvF5sVl5Jp70gAAAAAAKAGUUqhXjIMQy/8o6v6hjdTVn6Rbp21QamZefaOBQAAAAAAagilFOotV2eL3h/TS+EBXko+mas7Pt2kvMJie8cCAAAAAAA1gFIK9VoTT1d9fMv5auLpoq0HT2ryf7bKajXtHQsAAAAAAJwjSinUe+EBXnp/dC+5OBn6afsRvbY0zt6RAAAAAADAOaKUgkPo29ZfL11zniTpnRV79c3Gg3ZOBAAAAAAAzgWlFBzGtb1a6t5L2kuSHpu/Xb8nHrNzIgAAAAAAcLac7R0AsMWkyzoo6Vi2ftp2RLfO2qAQX3cln8xVeICXJkZHKCYq1N4RAQAAAABANdh1ptTKlSt1xRVXqHnz5jIMQ999913ZfYWFhXrkkUfUtWtXeXl5qXnz5rr55pt1+PBh+wWG3Vkshl77Zze18fdUTkGxEtOzlV9kVVxKpsbPidWiHUfsHREAAAAAAFSDXUup7OxsdevWTe+8806F+3JychQbG6snn3xSsbGxmjdvnuLi4nTllVfaISnqE3cXJzk7lT91TUmGIc1YnmCfUAAAAAAAwCZ2Xb43bNgwDRs2rNL7/Pz8tHTp0nJjb7/9tvr06aMDBw6oVatWdRER9dTB4zkVxkxTSkzLtkMaAAAAAABgK4faU+rUqVMyDENNmjSp8jH5+fnKz88v+zwjI0NSyXLAwsLC2o5Yq0rzO/r7qAlt/D0VfzRL5mnj4QGefH3qEc5ZOBrOWTgazlk4Gs5ZOBrOWTia+nLOVvf1DdM0T/+93i4Mw9D8+fN19dVXV3p/Xl6e+vfvr8jISH3++edVHueZZ57R1KlTK4x/8cUX8vT0rKm4sLOtxwx9HO8kQ6ZMGWXjFwQW68b29eKUBgAAAACgUcrJydFNN92kU6dOydfXt8rHOUQpVVhYqGuvvVaHDh3SL7/88rdvqLKZUmFhYUpPT//b5zmCwsJCLV26VJdddplcXFzsHcfuFu88qrd/2avE9Bz5ujsrPatAhiG9fUM3DekcbO94EOcsHA/nLBwN5ywcDecsHA3nLBxNfTlnMzIyFBAQcMZSqt4v3yssLNR1112n/fv36+effz5jseTm5iY3N7cK4y4uLg3mh0hDei/nYkT3lhrRvaUkyTRNPf7dDn2x7oAmfbNdX9zhpV6tm9o5IUpxzsLRcM7C0XDOwtFwzsLRcM7C0dj7nK3ua9v16ntnUlpIJSQkaNmyZfL397d3JNRThmHo2Su7aHBkkPKLrLp99gYlpmXZOxYAAAAAAKiCXUuprKwsbdmyRVu2bJEkJSUlacuWLTpw4IAKCws1cuRIbdy4UZ9//rmKi4uVkpKilJQUFRQU2DM26ilnJ4veuqmHurX004mcQo39ZL3SMvPP/EQAAAAAAFDn7FpKbdy4UT169FCPHj0kSZMmTVKPHj301FNPKTk5WT/88IMOHTqk7t27KzQ0tOxjzZo19oyNeszT1Vn/d8v5au3vqYPHc3XrrA3Kzi+ydywAAAAAAHAau+4pNWjQIP3dPuv1ZA92OJgAbzfNHtdH17y3RtuTT+neL2L14c295exUr1erAgAAAADQqPBbOhqkNgFe+r+xveXuYtGKuDQ9+f0OSk4AAAAAAOoRSik0WD1aNdVbN/aUxZC+XH9Qb/28x96RAAAAAADAnyil0KBd1jlYU6+KkiS9vjRe32w8aOdEAAAAAABAopRCIzDmgtb616B2kqRH523Xr/Fpdk4EAAAAAAAopdAoPDy0o/7Ro4WKrKbunrNJO5JP2TsSAAAAAACNGqUUGgXDMPTyteepf3t/ZRcUa9ysDTp4PMfesQAAAAAAaLQopdBouDpb9N7oXooM8VFaZr5u+WS9TuYU2DsWAAAAAACNEqUUGhVfdxd9Mu58hfq5a29atu74dKPyCovtHQsAAAAAgEaHUgqNTqifh2aN6yMfd2dt2HdC5z+/TB2eWKiY6Su1aMcRe8cDAAAAAKBRoJRCo9QxxEe3X9RWkpSZV6SCIqviUjI1fk4sxRQAAAAAAHWAUgqN1sLTyidTkmFIM5Yn2CcQAAAAAACNCKUUGq2k9OwKY6YpJaZVHAcAAAAAADWLUgqNVniAl4xKxls08ajzLAAAAAAANDaUUmi0JkZHlC3Z+6sTOQVKzcizSyYAAAAAABoLSik0WjFRoZo5uqciQ3zk5mxRh2BvBfu66UROoe74dKNyC4rtHREAAAAAgAbL2d4BAHuKiQpVTFRo2ef7j2Xr6nd+09ZDpzT5my16+8aeslgqW+QHAAAAAADOBTOlgL9o7e+l98f0louToQXbU/Tqkjh7RwIAAAAAoEGilAJO0ye8mV665jxJ0ru/7NU3Gw/aOREAAAAAAA0PpRRQiWt7tdS9l7SXJD02f7t+Tzxm50QAAAAAADQslFJAFSZd1kGXdw1VYbGp8XM2KSk9296RAAAAAABoMCilgCpYLIZeu66buoU10cmcQt02a4NO5hTYOxYAAAAAAA2CzVffS0pK0qpVq7R//37l5OQoMDBQPXr00IUXXih3d/fayAjYjbuLkz68uZf+8c4aJaZn619zYjX71j5ydabPBQAAAADgXFT7N+vPP/9cffr0Ubt27fTII4/ou+++06pVq/TRRx8pJiZGwcHBuvvuu7V///7azAvUuSAfd300tre8XJ20NvGYnvxuh0zTtHcsAAAAAAAcWrVKqR49eujNN9/ULbfcov379+vIkSPatGmTVq9erT/++EMZGRn6/vvvZbVa1bt3b33zzTe1nRuoU51CffX2TT1lMaSvNx7UBysT7R0JAAAAAACHVq1S6qWXXtK6det09913KywsrML9bm5uGjRokGbOnKndu3erbdu2NR4UsLdLIoP05IjOkqSXFu3W4p0pdk4EAAAAAIDjqlYpNXTo0Gof0N/fX7169TrrQEB9dku/NhpzQWuZpjTxqy3akXzK3pEAAAAAAHBINu/WHBsbq+3bt5d9/v333+vqq6/WY489poICrkyGhs0wDD19RWdd3CFQuYXFum32BqWcyrN3LAAAAAAAHI7NpdRdd92l+Ph4SVJiYqJuuOEGeXp66ptvvtHDDz9c4wGB+sbZyaK3b+qhiCBvHc3I122zNyg7v8jesQAAAAAAcCg2l1Lx8fHq3r27JOmbb77RxRdfrC+++EKzZs3S3LlzazofUC/5urvo41vOl7+Xq3YeztCNH/6umOkr1fGJhYqZvlKLdhyxd0QAAAAAAOo1m0sp0zRltVolScuWLdPw4cMlSWFhYUpPT6/ZdEA9FtbMUx/c3FvOFkPbDp3S7pRM5RdZFZeSqfFzYimmAAAAAAD4GzaXUr1799a0adP02Wef6ddff9Xll18uSUpKSlJwcHCNBwTqs16tmyrIx63cmCnJMKQZyxPsEwoAAAAAAAdgcyk1ffp0xcbG6t5779Xjjz+u9u3bS5K+/fZb9evXr8YDAvXdseyKG/ybppSYlm2HNAAAAAAAOAZnW59w3nnnlbv6XqlXXnlFTk5ONRIKcCThAV6KS8mU+ZcxQ1LbQC97RQIAAAAAoN6zeaaUJJ08eVIfffSRHn30UR0/flyS9Mcffyg1NbVGwwGOYGJ0RMmSvb+MmZLuvzTCTokAAAAAAKj/bC6ltm3bpoiICL388st69dVXdfLkSUnSvHnz9Oijj9Z0PqDei4kK1czRPRUZ6iMXJ6OsnEpMZ/keAAAAAABVsbmUmjRpksaNG6eEhAS5u7uXjQ8fPlwrV66s0XCAo4iJCtXCCRcr4fnheunarpKk15bEac1erkgJAAAAAEBlbC6lNmzYoLvuuqvCeIsWLZSSklIjoQBHdl3vMI3s1VJWU7r/y806mpFn70gAAAAAANQ7NpdSbm5uysjIqDAeHx+vwMDAGgkFODLDMPTcVVGKDPFRelaB7vtis4qKrfaOBQAAAABAvWJzKXXllVfq2WefVWFhoaSSX8APHDigRx55RNdee22NBwQckYerk94d1VPebs5av++4XlkSZ+9IAAAAAADUKzaXUq+99pqysrIUFBSk3NxcDRw4UO3bt5ePj4+ef/752sgIOKS2gd56ZeR5kqT3f03Ukp0sbwUAAAAAoJSzrU/w8/PT0qVL9dtvv2nr1q3KyspSz549FR0dXRv5AIc2rGuobrsoXP+3OkmTv9mqn0J81crf096xAAAAAACwO5tnSn366afKz89X//79dffdd+vhhx9WdHS0CgoK9Omnn9ZGRsChTRkWqV6tmyozr0j/+nyT8gqL7R0JAAAAAAC7s7mUGjdunE6dOlVhPDMzU+PGjauRUEBD4uJk0ds39VAzL1ftPJyhqf/9w96RAAAAAACwO5tLKdM0ZRhGhfFDhw7Jz8+vRkIBDU2on4dm3NBdhiF9uf6A5m46ZO9IAAAAAADYVbX3lOrRo4cMw5BhGBo8eLCcnf/31OLiYiUlJSkmJqZWQgINwYCIQE0c3EFvLIvX499tV5cWvooM8bV3LAAAAAAA7KLapdTVV18tSdqyZYuGDh0qb2/vsvtcXV3Vpk0bXXvttTUeEGhI7ru0vTYdOKGV8Wm6e06svr+3v3zcXewdCwAAAACAOlftUurpp5+WJLVp00bXX3+93N3day0U0FBZLIamX99dl7+5Sonp2Zoyd7vevqlHpUtiAQAAAABoyGzeU2rs2LEUUsA5aOblqndG9ZSzxdBP249o1pp99o4EAAAAAECds7mUslgscnJyqvIDwJn1bNVUj1/eSZL0/E+7tGn/CTsnAgAAAACgblV7+V6pefPmlVtqVFhYqM2bN2v27NmaOnVqjYYDGrJb+rXRxn0n9NP2I7r3i1j9dP8ANfNytXcsAAAAAADqhM2lVOmG5381cuRIdenSRV9//bVuu+22msgFNHiGYeila7tq15EMJaZna8JXmzVrXB85WdhfCgAAAADQ8Nm8fK8qF1xwgZYvX15ThwMaBR93F707uqfcXSxalZCuvi8sU8cnFipm+kot2nHE3vEAAAAAAKg1NVJK5ebm6s0331SLFi1q4nBAoxIZ4qvre4dJktKzCpRfZFVcSqbGz4mlmAIAAAAANFg2L99r2rRpuT2lTNNUZmamPD09NWfOnBoNBzQW65KOl/vclGQY0ozlCYqJCrVPKAAAAAAAapHNpdT06dPLfW6xWBQYGKi+ffuqadOmNZULaFSS0rMrjJmmlJhWcRwAAAAAgIbA5lJq7NixtZEDaNTCA7wUl5Ip87TxtgFedskDAAAAAEBts7mUkqSTJ09q/fr1Sk1NldVqLXffzTffXCPBgMZkYnSExs+JlWGUzJAqFR5IKQUAAAAAaJhsLqX++9//atSoUcrKypKvr2+5/aUMw6CUAs5CTFSoZo7uqRnLE5SYli1/L1cdPpWnBdtT9MPWw7qyW3N7RwQAAAAAoEbZXEpNnjxZt956q1544QV5enrWRiagUYqJCi23qfmLC3bp/ZWJeuibrWrj76nzWjaxXzgAAAAAAGqYxdYnJCcn6/7776eQAmrZwzGRujQySPlFVt3x6UYdzcizdyQAAAAAAGqMzaXU0KFDtXHjxtrIAuAvnCyGZtzQXRFB3jqaka87P92ovMJie8cCAAAAAKBG2Lx87/LLL9dDDz2kP/74Q127dpWLi0u5+6+88soaCwc0dj7uLvpobG9d9c5v2nrolB6Zu03Tr+9ebi83AAAAAAAckc2l1B133CFJevbZZyvcZxiGiouZyQHUpNb+Xnp3VE/d/H/r9f2Ww+oY4qO7B7W3dywAAAAAAM6Jzcv3rFZrlR8UUkDt6NcuQE9f2UWS9MriOC3ZmWLnRAAAAAAAnBubSykA9jHmgtYac0FrmaY08est2p2SYe9IAAAAAACctWot33vzzTd15513yt3dXW+++ebfPvb++++vkWAAKnrqis7ak5qltYnHdPvsjfr+nv7y93azdywAAAAAAGxWrVLqjTfe0KhRo+Tu7q433nijyscZhkEpBdQiFyeL3h3VU1e/+5v2H8vRv+bEas7tfeXqzKRHAAAAAIBjqdZvsklJSfL39y/7c1UfiYmJNr34ypUrdcUVV6h58+YyDEPfffdduftN09RTTz2l0NBQeXh4KDo6WgkJCTa9BtDQNPVy1Uc395a3m7PW7zuup77fIdM07R0LAAAAAACb2HV6RXZ2trp166Z33nmn0vv//e9/680339TMmTO1bt06eXl5aejQocrLy6vjpED9EhHso7du7CHDkL7acFCz1uyzdyQAAAAAAGxSreV7f2Wapr799lutWLFCqampslqt5e6fN29etY81bNgwDRs2rMrXmT59up544gldddVVkqRPP/1UwcHB+u6773TDDTfYGh1oUC6JDNKjwyL1woLdeu7HP9Qu0FsXdwi0dywAAAAAAKrF5plSEydO1JgxY5SUlCRvb2/5+fmV+6gpSUlJSklJUXR0dNmYn5+f+vbtq7Vr19bY6wCO7I4BbXVtz5aymtK9X8QqMS3L3pEAAAAAAKgWm2dKffbZZ5o3b56GDx9eG3nKpKSkSJKCg4PLjQcHB5fdV5n8/Hzl5+eXfZ6RkSFJKiwsVGFhYS0krTul+R39faBmTb0iUolpmdp88JRum7VB39zVV34eLvaOJYlzFo6HcxaOhnMWjoZzFo6GcxaOpr6cs9V9fZtLKT8/P7Vt29bmQHXlxRdf1NSpUyuML1myRJ6ennZIVPOWLl1q7wioZ64JkpKOOinpWI76v/Szik0pyEOKaWlVN3/7b4LOOQtHwzkLR8M5C0fDOQtHwzkLR2PvczYnJ6daj7O5lHrmmWc0depUffzxx/Lw8LA5WHWFhIRIko4eParQ0NCy8aNHj6p79+5VPu/RRx/VpEmTyj7PyMhQWFiYhgwZIl9f31rLWxcKCwu1dOlSXXbZZXJxqR8zYVB/ZAXs08uL45VvNSRJR3Kkj+Od9PYN3TS0S/AZnl07OGfhaDhn4Wg4Z+FoOGfhaDhn4WjqyzlbumrtTGwupa677jp9+eWXCgoKUps2bSq8ydjYWFsPWanw8HCFhIRo+fLlZSVURkaG1q1bp3/9619VPs/NzU1ubm4Vxl1cXBrMD5GG9F5Qc77fekSGpNJ5UaYkw5De+TVRI7q3tGMyzlk4Hs5ZOBrOWTgazlk4Gs5ZOBp7n7PVfW2bS6mxY8dq06ZNGj16tIKDg2UYhs3hSmVlZWnPnj1lnyclJWnLli1q1qyZWrVqpYkTJ2ratGmKiIhQeHi4nnzySTVv3lxXX331Wb8m0FAlpWfr9IV6pintTcu2Sx4AAAAAAP6OzaXUTz/9pMWLF+uiiy465xffuHGjLrnkkrLPS5fdjR07VrNmzdLDDz+s7Oxs3XnnnTp58qQuuugiLVq0SO7u7uf82kBDEx7gpbiUzArFlCHp4PEchTVrGHuqAQAAAAAaBoutTwgLC6uxvZkGDRok0zQrfMyaNUuSZBiGnn32WaWkpCgvL0/Lli1Thw4dauS1gYZmYnRE2ZI9qaSMkqT8IquufHu1fk88Zq9oAAAAAABUYHMp9dprr+nhhx/Wvn37aiEOgLMVExWqmaN7KjLER27OFkWG+ujFa7qqaws/ncgp1OiP1unzdfvtHRMAAAAAAElnsXxv9OjRysnJUbt27eTp6Vlh86rjx4/XWDgAtomJClVMVGi5sau7t9DDc7fpv1sP6/H5O7T7SKaeuqKzXJxs7qQBAAAAAKgxNpdS06dPr4UYAGqLh6uT3ryhuyJDfPTqkjh99vt+JaRm6t1RvdTMy9Xe8QAAAAAAjdRZXX0PgGMxDEP3XNJeHYJ9NPGrzfo98biueme1Prr5fHUM8bF3PAAAAABAI1St9TvZ2bZdUt7WxwOoG5d1Dtb8e/qrVTNPHTyeq2ve/U1LdqbYOxYAAAAAoBGqVinVvn17vfTSSzpy5EiVjzFNU0uXLtWwYcP05ptv1lhAADWrQ7CPvr+nvy5s66/sgmLd+dkmvf1zgkzTtHc0AAAAAEAjUq3le7/88osee+wxPfPMM+rWrZt69+6t5s2by93dXSdOnNAff/yhtWvXytnZWY8++qjuuuuu2s4N4Bw09XLVp7f10bQf/9Dstfv16pJ47U7J1Csju8nD1cne8QAAAAAAjUC1SqmOHTtq7ty5OnDggL755hutWrVKa9asUW5urgICAtSjRw99+OGHGjZsmJyc+IUWcAQuThZNvSpKHUN89dT3O/TjtiPadyxbH4zpreZNPOwdDwAAAADQwNm00XmrVq00efJkTZ48ubbyAKhjN/VtpXaBXvrX57HakZyhK9/+TeP6t9Z/tx5RUnq2wgO8NDE6QjFRofaOCgAAAABoQKq1pxSAhq1vW399f09/RYb4KD0rX68sLlnOl19kVVxKpsbPidWiHVXvKQcAAAAAgK0opQBIksKaeWruv/rJx638BEpTkmFIM5Yn2CcYAAAAAKBBopQCUMbLzVn5xdYK46Yp7UnNskMiAAAAAEBDRSkFoJy2AV4yKhkvLDY18r01Wr7rqEzTrPNcAAAAAICGhVIKQDkToyPKluxJKiuonC2GNu4/odtmb1TM9FX6bnOyiiqZVQUAAAAAQHWcVSm1atUqjR49WhdeeKGSk5MlSZ999plWr15do+EA1L2YqFDNHN1TkSE+cnO2KDLURzNH99KaKZfqrovbysvVSXFHMzXx6y0a9Oov+nTtPuUWFNs7NgAAAADAwTif+SHlzZ07V2PGjNGoUaO0efNm5efnS5JOnTqlF154QQsWLKjxkADqVkxUqGKiQiuMPzq8k+4e1F5z1u3Xx6uTdOhErp76fqdmLEvQuP5tNOaCNvLzdLFDYgAAAACAo7F5ptS0adM0c+ZMffjhh3Jx+d8vn/3791dsbGyNhgNQ//h5uuieS9rrtymX6rmruqhlUw8dyy7Qq0vi1f/ln/Xigl06mpGnRTuOaMTbazT5dyeNeHuNFu04Yu/oAAAAAIB6xOaZUnFxcbr44osrjPv5+enkyZM1kQmAA3B3cdKYC9voxj6t9NP2I3rvl73anZKp91cm6v9WJ6nIasqQZMpQ/NEsjZ8Tq5mje1Y6AwsAAAAA0PjYPFMqJCREe/bsqTC+evVqtW3btkZCAXAczk4WXdW9hRZOGKBPbjlffdo0U5G15Op8pdfoM1WyYfq/F8WpoIjN0QEAAAAAZzFT6o477tCECRP08ccfyzAMHT58WGvXrtWDDz6oJ598sjYyAnAAhmHoksggXRIZpIjHF6iw2Cx3vykpMT1bXZ5epHaB3uoU6qtOoT6KDPFVZKiPAr3dZJRe8u9Pi3Yc0fRlCUpKz1Z4gJcmRkcw0woAAAAAGgibS6kpU6bIarVq8ODBysnJ0cUXXyw3Nzc9+OCDuu+++2ojIwAH0y7QW3EpmTJPG7cYUmGxqd0pmdqdkqn5m/93n7+XqyJLS6oQH53ILtALC3f/uQRQikvJZAkgAAAAADQgNpdShmHo8ccf10MPPaQ9e/YoKytLnTt3lre3d23kA+CAJkZHaPycWBmGZJoqu313VE91ae5XUkodydDulEztSsnQvvRsHcsu0G97jum3PcfKHavcEkBDmrE8gVIKAAAAABoAm0upUq6ururcuXNNZgHQQMREhWrm6J6avixee45mqn2wjyZGd1RMVIgkKayZpy7rHFz2+NyCYiWkZmr3kZKSaveRTK1NPFbhuKZZMmNqxe5U9W8fIFdnm7fFAwAAAADUEzaXUnl5eXrrrbe0YsUKpaamymotv2lxbGxsjYUD4LhiokI1uGOAFixYoOHD+8nFxaXKx3q4Oum8lk10Xssm/3v+9JWVLgG0mtK4WRvUxNNFw6JCdMV5zdW3rb+cLIYAAAAAAI7D5lLqtttu05IlSzRy5Ej16dOnwsbEAFATqloCeEnHQG1PzlB6Vr6+XH9QX64/qEAfN13eNVRXdGuunq2a8HMJAAAAAByAzaXUjz/+qAULFqh///61kQcAJP1vCeCM5QlKTMtW20AvTRjcQTFRISq2mlqXeEz/3XZYC7anKC0zX7PW7NOsNfvUoomHRnQL1RXnNVeX5r4yDIOr+AEAAABAPWRzKdWiRQv5+PjURhYAKCcmKrTS8sjJYqhf+wD1ax+gqVdG6bc96frv1sNavDNFySdz9f6viXr/10S1DfBSZKivFmw/wlX8AAAAAKCesbmUeu211/TII49o5syZat26dW1kAoBqc3W26JLIIF0SGaS8wmL9EpeqH7Ye1vJdqUpMz1Zierak067iJ2n6Mse9il9NzPyqL8cAAAAA0HjZXEr17t1beXl5atu2rTw9PStsXnz8+PEaCwcAtnB3cSqbXZWVX6RlfxzVpP9skfW03dJNSbtTMjXkjV/VOdRXnUJ91bl5yW2At1ut5aupImj8nNhzmvlVX45RehyKLQAAAKBxsrmUuvHGG5WcnKwXXnhBwcHBbCgMoF7ydnPW1T1aaOaveyu9ip8kxR/NUvzRLH235XDZWJCPW1lJVVpYhQd4aekfKWddnhQVW/XfbUf0wNdbKpQ4EwdHqFtYE+UXFSuv0Kr8omLlF1mVV1is/EKr8ous5e5btCNFUvmZX5L0wNdb9N4ve1VkNVVsNf9ya1VxsVluPDOvsNJj/OvzWHm7OsswJIvFkMUwZDH0523Jnw3DkMUipZzKq/QYk/+zVfM3J8vdxUkeLk5yd3GSm4tF7s5O8nB1kruzRe5/ju86ckrvr0yq8DV568YeuqJb82p9bUtRbgEAAACOx+ZSas2aNVq7dq26detWG3kAoEZVdRW/l67pqiBfN+06kqk/Dmdo15EMJR3LVmpmvlIz0/RrfFrZMVycDBUW/6/W2v1nedInvJmaeboqt7BYeWUfVuUWFpcb++tzTy9xpi9PqJH3mVto1dZDp87pGKYpZeYXndMxsguKtXjnUdte97Tb+77crIe/3SZfD2f5ebjI191Fvh4u8nV3/vPWpWTcw1m+7i6KS8nU9OUJ7BsGAAAAOBibS6nIyEjl5ubWRhYAqHF/dxU/Sbo0Mrjssdn5RdqdkqldRzL0x5EM/XE4Q3EpmcotLK702OuTzn25siEpqoWf3F0scnN2ktufM4ncnC1yKx37y32z1+xTamZ+hWO0aOqhqVd2kZPFkLPFUnLrZPz5uVFu/M7PNiopLbvc7DFDUttAL3009nxZTVOmacpqSsVW88/PJetfxiZ9vUUHjudUOEaIn7vuvqS98guLlVtQrLw/Z3mVFnZl5V1RsdbsOVbpDDZJZcXe0Yz8Kh5R0enl1uPzdyi3sFjtA33ULshLnq42/ycPAAAAQC2y+V/oL730kiZPnqznn39eXbt2rbCnlK+vb42FA4CaUNVV/E7n5easXq2bqlfrpmVjxVZTkU8uLDfbqZSTxdAzV3aRu7NFHq7/W65W8mGRh0vpkjUn3fDB74o/Wn4ZoWFIkSE++u99F1X7vbQL9Kp05tcTl3fW4E7BZz6ApIeHdqz0GA8NjVR4gFe1jvHo8MhKj/H0FV3KCr8ziZm+ssLSSsOQIoK89dHN5ysjr1AZuYV/3hYpI69Qp3JLx4rK7tu470Sl5dax7AI98PXWss9bNPFQRLC32gd6l9wGeat9oI/8PEv+O7ZoxxG9sTRee1Od9G7iGj1wWQdmWgEAAAC1yOZSKiYmRpI0ePDgcuOmacowDBUXVz6jAAAckZPFULtA70rLkw7B3hpzQfWuQvrAZZUvI5wwuINNec4088uRjlHV0spJl3VUK3/P6meppNySpKaeLuoQ7KO9aVlKzypQ8slcJZ/M1S9xaeUeF+jjpqaeLoo/mvXniKH4o1ksAQQAAABqmc2l1IoVK2ojBwDUW1WVJ7YUSjVR4vz1WOdalNSHY9TU16Sqv58Xrzmv7Fgnsgu0Jy1LCUeztCc1SwmpmdqbmqXDp/KUlpmvtNOWRJYWXK8tiaeUAgAAAGqJzaXUwIEDayMHANRbNVWe1EQR1NDUVDl2pr+fpl6uOt+rmc5v06zcc7Pyi7Q3NUvXvrdGRdaKiwATUrM05v/WaWSvlhrSOUQerk7nlBUAAADA/1SrlNq2bZuioqJksVi0bdu2v33seeedVyPBAKA+oVCq387278fbzVndwpqofVDFJZqlViWka1VCunzcnDWiW6iu7dlSvVo3lWEY5x4cAAAAaMSqVUp1795dKSkpCgoKUvfu3WUYhkyz4j/d2VMKAOCIqloC+NxVXZSWVaB5sYd06ESuvlx/UF+uP6jwAC9d27OF/tGzpVo08bB3fAAAAMAhVauUSkpKUmBgYNmfAQBoSEqXAE5fFq89RzPVPthHE6M7li0BnDg4QuuSjuvbTYe0cMcRJaVn69Ul8Xptabz6tfPXtT1bKiYqRCvj0zR9WYKS0rMVHuClidERzLADAAAAqlCtUqp169ZycnLSkSNH1Lp19a40BQCAI4mJCtXgjgFasGCBhg/vJxcXl7L7LBZDF7bz14Xt/PXsVV20cEeKvt10UL8nHtdve47ptz3H9Oi87covsspQyUbpcSmZXMEPAAAA+BvV3ui8suV6AAA0Nl5uzhrZq6VG9mqpg8dzNC82WXNjD+nA8RxJ/7tynynJkDRjeQKlFAAAAFAJi70DAADgqMKaeWpCdIR+fWiQXJwqbnxeOmNqZXyarJVc3Q8AAABozKo9U0qSPvroI3l7e//tY+6///5zCgQAgKMxDEPtAiu/gp/VlG7+eL3CmnnohvNb6Z+9WyrIx90uOQEAAID6xKZSaubMmXJycqryfsMwKKUAAI1SVVfwG9QhUJsOnNDB47l6ZXGc3lgar8s6B+vGPq10UfsAWSwVZ1gBAAAAjYFNpdTGjRsVFBRUW1kAAHBYpVfwm7E8QYlp2Wob6KUJgzsoJipEuQXF+nHbYX25/oBiD5zUwh0pWrgjhdlTAAAAaNSqXUoZBv8nFwCAvxMTFVrppuYerk76Z+8w/bN3mHanZOjLdQc0b3NyhdlTN/Vtpf7tArTkjxRNX5agpPRshQd4aWJ0BJulAwAAoMHh6nsAANShyBBfTb0qSlOGdap09pS/t6uOZRXI0P82Sh8/J1YzR/ekmAIAAECDUu2r7z399NNn3OQcAABUT+nsqXl399eiiQM09sLW8nF31rGsAkkq2zDdVMn+VDOWJ9gtKwAAAFAbbCqlPD09azMLAACNUunsqfWPRcu5ko3PTVNKOJqlzLxCO6QDAAAAake1SykAAFC7PFyd1D7IW5Xt4lhkNdX3heV6fP527TqSUefZAAAAgJpGKQUAQD0yMTqibMmepLKCKsTPXTkFxfp83QENm7FK/5y5Rt9vSVZBkdVeUQEAAIBzUu2NzgEAQO2LiQrVzNE9NWN5ghLTstU20EsTBnfQ0C7B+j3xuOb8vl+Ld6Zow74T2rDvhJ7z/kPXnx+mm/q2VosmHvaODwAAAFQbpRQAAPVMTFRopVfau7Cdvy5s56+jGXn6av1BfbF+v45m5OudFXv13i97dWlksG6+sLUuah+gJX+kaPqyBCWlZys8wEsToyO4eh8AAADqlWqVUj169JBhVLbDRUWxsbHnFAgAAPy9YF93TYiO0N2XtNOyP47qs9/3a83eY1q266iW7TqqQG9XpWUVyFDJ1fviUjI1fk6sZo7uSTEFAACAeqNapdTVV19dyzEAAICtXJwsGtY1VMO6hmpPaqbm/H5AczcdUlpWgaSSQqr01jCkGcsTKKUAAABQb1SrlHr66adrOwcAADgH7YN89MyVXfTQ0I7qNnWJiqxmuftNU0o4mqXCYqtcnLjOCQAAAOyPf5UCANCAeLk5q32QtypbdF9kNdX/pZ81fVm8UjPz6jwbAAAA8FfVminVtGnTau8pdfz48XMKBAAAzs3E6AiNnxMrwyiZIVW6t5Svu7NSM/M1fVmC3lmxR8OiQjW2Xxv1bNWk2v+dBwAAAGpKtUqp6dOn13IMAABQU2KiQjVzdE/NWJ6gxLRstQ300oTBHXRpZJAW7UzR7DX7tGn/Cf2w9bB+2HpYUS18NfbCNrqiW3O5uzjZOz4AAAAaiWqVUmPHjq3tHAAAoAbFRIVWuqn5ld2a68puzbUj+ZRmr9mn77ce1o7kDD307Ta9sGCXbujTSqMvaK0WTTzskBoAAACNSbVKqdPt3btXn3zyifbu3asZM2YoKChICxcuVKtWrdSlS5eazggAAGpYVAs/vfLPbnp0eCd9veGg5vy+X8knc/XeL3v1/q97dVnnYHUK9dWiHSlKSs9WeICXJkZHcPU+AAAA1BibNzr/9ddf1bVrV61bt07z5s1TVlaWJGnr1q1cpQ8AAAfTzMtV/xrUTisfvkTvj+ml/u39ZTWlxTuPavqyBO1OyVR+kVVxKZkaPydWi3YcsXdkAAAANBA2l1JTpkzRtGnTtHTpUrm6upaNX3rppfr9999rNBwAAKgbThZDQ7uE6PPbL9DSBy5WE0+Xcvebf96+sjiu7sMBAACgQbK5lNq+fbv+8Y9/VBgPCgpSenp6jYQCAAD2ExHso9yC4krv25uWrXGfrNcvcamyWs1KHwMAAABUh82lVJMmTXTkSMWp+5s3b1aLFi1qJBQAALCv8AAvGVXctyIuTbd8skGDX/9Vn/yWpMy8wjrNBgAAgIbB5lLqhhtu0COPPKKUlBQZhiGr1arffvtNDz74oG6++ebayAgAAOrYxOgImZKMP5up0tvnruqiW/uHy8fNWUnp2Zr63z90wQvL9dT3O7QnNdNueQEAAOB4bL763gsvvKB77rlHYWFhKi4uVufOnVVcXKybbrpJTzzxRG1kBAAAdSwmKlQzR/fUjOUJSkzLVttAL00Y3EExUSGSpMlDOmje5mR9umafElKz9Ona/fp07X5d1D5AY/u10aWRQXKyVDXXCgAAADiLUsrV1VUffvihnnzySe3YsUNZWVnq0aOHIiIiaiMfAACwk5ioUMVEhVZ6n5ebs8Zc0Fqj+7bS2r3HNGvNPi3bdVSr96Rr9Z50hTXz0JgLWuu63mH6PfGYpi9LUFJ6tsIDvDQxOqLK4wIAAKDxsLmUSkxMVNu2bdWqVSu1atWqNjKVKS4u1jPPPKM5c+YoJSVFzZs31y233KInnnhChsH/fQUAwN4Mw1C/9gHq1z5AB4/naM66/fp6w0EdPJ6rFxbs1iuL41RYbMpQyRX84lIyNX5OrGaO7kkxBQAA0MjZXEq1b99eLVu21MCBAzVo0CANHDhQ7du3r41sevnll/Xee+9p9uzZ6tKlizZu3Khx48bJz89P999/f628JgAAODthzTz16LBOmji4g37YmqxZa/Zr15EMSSWFVOmtYUgzlidQSgEAADRyNm90fvDgQb344ovy8PDQv//9b3Xo0EEtW7bUqFGj9NFHH9VouDVr1uiqq67S5ZdfrjZt2mjkyJEaMmSI1q9fX6OvAwAAao6Hq5OuP7+VFtx/kVycKs5sNk0p/miWUjPz7JAOAAAA9YXNpVSLFi00atQoffDBB4qLi1NcXJyio6P1n//8R3fddVeNhuvXr5+WL1+u+Ph4SdLWrVu1evVqDRs2rEZfBwAA1DzDMNQu0FuVLbgvtprq/9LPuv/Lzdq0/7hM06zkUQAAAGjIbF6+l5OTo9WrV+uXX37RL7/8os2bNysyMlL33nuvBg0aVKPhpkyZooyMDEVGRsrJyUnFxcV6/vnnNWrUqCqfk5+fr/z8/LLPMzJKlg0UFhaqsLCwRvPVtdL8jv4+0HhwzsLRcM7WvHsHtdW9X22VYZTMkCrdWyrc31NJx3L0w9bD+mHrYXUO9dHovq10xXkhcndxsndsh8E5C0fDOQtHwzkLR1Nfztnqvr5h2vi/Jl1dXdW0aVONGjVKgwYN0oABA9S0adOzCnkmX331lR566CG98sor6tKli7Zs2aKJEyfq9ddf19ixYyt9zjPPPKOpU6dWGP/iiy/k6elZKzkBAEDVth4ztOiQRam5UpCHFNPSqm7+pg5mSatSLIpNN1Rolsyn8nQ2dUGgqf4hVgW42zk4AAAAzkpOTo5uuukmnTp1Sr6+vlU+zuZS6uqrr9bq1avl6uqqQYMGlX106NDhnEOfLiwsTFOmTNE999xTNjZt2jTNmTNHu3fvrvQ5lc2UCgsLU3p6+t9+IRxBYWGhli5dqssuu0wuLi72jgOcEecsHA3nrH2cyCnQt7HJ+mL9IR06kSupZDP0QR0CNKZvK/Vv56+lu1L11oq9SjqWo3B/T913STsN7RJs5+T2xzkLR8M5C0fDOQtHU1/O2YyMDAUEBJyxlLJ5+d53330nSdq2bZt+/fVXLVmyRE8++aScnZ01aNAgff7552cd+nQ5OTmyWMpve+Xk5CSr1Vrlc9zc3OTm5lZh3MXFpcH8EGlI7wWNA+csHA3nbN0K8nPR3Zd00F0DI/RLXKpmr92vlfFpWhGXrhVx6Qr0dlVaVkHZ0r/4o1m696utmjm6J1fw+xPnLBwN5ywcDecsHI29z9nqvrbNpVSprl27qqioSAUFBcrLy9PixYv19ddf12gpdcUVV+j5559Xq1at1KVLF23evFmvv/66br311hp7DQAAUD84WQwN7hSswZ2ClZiWpTm/H9A3mw4qLatAUkkhVXprGNKM5QmUUgAAAA7M5qvvvf7667ryyivl7++vvn376ssvv1SHDh00d+5cpaWl1Wi4t956SyNHjtTdd9+tTp066cEHH9Rdd92l5557rkZfBwAA1C9tA7311BWd9fujg+VsqXj9PtOUEo5mKb+o2A7pAAAAUBNsnin15ZdfauDAgbrzzjs1YMAA+fn51UYuSZKPj4+mT5+u6dOn19prAACA+svLzVntg7wVl5Kp0zfBLLKa6vfiz7ru/DDd1KeVwppxQRMAAABHYnMptWHDhtrIAQAAUKmJ0REaPydWhlEyQ6p0b6mmni46ll2g937Zq5m/7tWlHYM0+sLWGhgRKEsls6sAAABQv9hcSiUkJOj777/Xvn37ZBiGwsPDdfXVV6tt27a1kQ8AADRyMVGhmjm6p2YsT1BiWrbaBnppwuAOiu4UpOW7UzXn9/1alZCu5btTtXx3qlo189Sovq30z95haublau/4AAAAqIJNpdSLL76oJ598UqZpKigoSKZpKi0tTVOmTNELL7ygBx98sLZyAgCARiwmKrTSTc2HdgnR0C4hSkzL0ufrDuibjQd14HiOXly4W68tjdeI80I15oLW6h7WRIt3pmj6sgQlpWcrPMBLE6Mj2CgdAADAjqq90fmKFSv0xBNP6IknnlB6erqOHDmilJSUslJqypQpWrlyZW1mBQAAqFTbQG89OaKz1j0WrX9fe56iWviqoMiqebHJ+se7a3TxKys0fk6s4lIylV9kVVxKpsbPidWiHUfsHR0AAKDRqvZMqZkzZ+r222/XM888U268WbNmevbZZ5WSkqL33ntPF198cU1nBAAAqBYPVyddd36Y/tm7pbYeOqXP1u7Xf7cd1sHjuZJUtlm6KckwpBnLE5gtBQAAYCfVnim1fv16jRkzpsr7x4wZo99//71GQgEAAJwLwzDUPayJXruum9Y9OlhOlWx8bppSwtEs5RcV2yEhAAAAql1KHT16VG3atKny/vDwcKWkpNREJgAAgBrT1MtVEUHequx6fEVWUxe8sFzP//SHEtOy6jwbAABAY1btUiovL0+urlVfwcbFxUUFBQU1EgoAAKAmTYyOKFuyJ6msoGrq6aITOYX6cFWSLn3tV9304e/6cdthFRRZ7RUVAACg0bDp6nsfffSRvL29K70vMzOzRgIBAADUtJioUM0c3VMzlicoMS1bbQO9NGFwB0V3CtIvcWn6Yv0BrYhL1Zq9x7Rm7zEFeLtqZK8w3dSnlVr5e9o7PgAAQINU7VKqVatW+vDDD8/4GAAAgPooJiq00k3NozsHK7pzsA6dyNHXGw7q6w0HlZqZr5m/7tXMX/dqQESARvVtpcGdgrV811FNX5agpPRshQd4aWJ0BBulAwAAnKVql1L79u2rxRgAAAD21bKppyYP6aj7B0do+a5UfbH+gFYlpGlVQrpWJaTL191ZGXlFMlRy9b64lEyNnxOrmaN7UkwBAACcBZuW7wEAADR0Lk4WxUSFKCYqRAeO5ejLDQf0zcaDSs8q2TvT/PNxpXtUzVieQCkFAABwFqq90TkAAEBj08rfU4/ERGrNlMFytlS8fp9pSvEpWVy5DwAA4CxQSgEAAJyBq7NF7YO8VbGWkopNU5e+9quue3+t5sUeUm5BcZ3nAwAAcESUUgAAANUwMTqibMme/nLbtYWfLIa0Pum4Jv1nq/q8sExPfrdDO5JP2S0rAACAI2BPKQAAgGqIiQrVzNE9NWN5ghLTstU20EsTBndQTFSIjpzK1bcbD+nrjQd16ESuPvt9vz77fb+iWvjq+t5hurJ7C/l5uNj7LQAAANQr1SqlMjIyqn1AX1/fsw4DAABQn8VEhVa6qXmon4fuGxyhey5przV7j+mrDQe0ZOdR7UjO0I7knZr20y5d3jVU158fpj7hzbR4Z4qmL0tQUnq2wgO8NDE6gs3SAQBAo1OtUqpJkyYyjMp2UaiouJh9FAAAQONksRi6KCJAF0UE6ER2geZvTtZXGw4o/miW5m1O1rzNyQrycVNqZr4MlVzBLy4lU+PnxGrm6J4UUwAAoFGpVim1YsWKsj/v27dPU6ZM0S233KILL7xQkrR27VrNnj1bL774Yu2kBAAAcDBNvVx160XhGte/jbYcPKmvNxzUD1sPKzUzX1JJIVV6axjSjOUJlFIAAKBRqVYpNXDgwLI/P/vss3r99dd14403lo1deeWV6tq1qz744AONHTu25lMCAAA4KMMw1KNVU/Vo1VRPjOis7lOXqMhqlnuMaUrxKZnaefiUujT3s1NSAACAumXz1ffWrl2r3r17Vxjv3bu31q9fXyOhAAAAGiJvN2e1D/JWZZsiFJvS5W+u1rAZq/R/q5OUnpVf5/kAAADqks2lVFhYmD788MMK4x999JHCwsJqJBQAAEBDNTE6omzJnv5y26tVU7k6WbTrSIae+/EPXfDCct0+e6MW7UhRQZHVbnkBAABqS7WW7/3VG2+8oWuvvVYLFy5U3759JUnr169XQkKC5s6dW+MBAQAAGpKYqFDNHN1TM5YnKDEtW20DvTRhcAfFRIXoZE6B/rvtiL7ddEhbD57Usl1HtWzXUTX1dNFV3VtoZK+W6tLct9oXoAEAAKjPbC6lhg8frvj4eL333nvavXu3JOmKK67Q+PHjmSkFAABQDTFRoZVuat7E01VjLmitMRe0VsLRTH0be0jzY5OVmpmvWWv2adaafYoM8dHIXi3l6+Gi/1uVqL2pTno3cY0euKwDG6UDAACHYnMpJZUs4XvhhRdqOgsAAAD+FBHso0eHddJDQzpq1Z50fbvpkJbuPKrdKZma9tOuvzzSUPzRLI2fE6uZo3tSTAEAAIdh855SkrRq1SqNHj1a/fr1U3JysiTps88+0+rVq2s0HAAAQGPn7GTRJR2D9M5NPbXh8WhNuzpK7i7l/wlXei2/V5fE131AAACAs2RzKTV37lwNHTpUHh4eio2NVX5+yZVhTp06xewpAACAWuTn6aLRF7SWaVZ+/57ULN02a4OW7zqqYmsVDwIAAKgnbC6lpk2bppkzZ+rDDz+Ui4tL2Xj//v0VGxtbo+EAAABQUXiAl6ra6nz57lTdNnujBrz8s95cnqCjGXl1mg0AAKC6bC6l4uLidPHFF1cY9/Pz08mTJ2siEwAAAP7GxOgImZJKL8JXejv1yi66Y0C4mni66PCpPL2+NF79XvpZd322Ub/Gp8nK7CkAAFCP2LzReUhIiPbs2aM2bdqUG1+9erXatm1bU7kAAABQhZioUM0c3VPTl8Vrz9FMtQ/20cTojoqJCpEkTR7SUYt2pOiLdQe0ft9xLd55VIt3HlWrZp66oU+Y/tkrTIE+bnZ+FwAAoLGzuZS64447NGHCBH388ccyDEOHDx/W2rVr9eCDD+rJJ5+sjYwAAAA4TUxUqAZ3DNCCBQs0fHi/ctsquLs46eoeLXR1jxaKP5qpL9Yd0NzYQzpwPEf/XhSnN5bGa0iXEEUEeWvRjhQlpWcrPMBLE6MjuHofAACoMzaXUlOmTJHVatXgwYOVk5Ojiy++WG5ubnrwwQd133331UZGAAAAnKUOwT565soueiQmUj9uO6zP1x3QloMn9dO2I+UeF5eSqfFzYjVzdE+KKQAAUCds3lPKMAw9/vjjOn78uHbs2KHff/9daWlpeu6552ojHwAAAGqAh6uT/tk7TN/d018/3X+Rmni4lLu/dLepaT/tUkGRte4DAgCARsfmUurWW29VZmamXF1d1blzZ/Xp00fe3t7Kzs7WrbfeWhsZAQAAUIO6NPdTbmFxpfcdOpGrPi8s09Pf79C2QydlmmyODgAAaofNpdTs2bOVm5tbYTw3N1effvppjYQCAABA7QoP8JJRybizxdDJnELNXrtfV779m4a8sVIzf92roxl5dZ4RAAA0bNXeUyojI0Omaco0TWVmZsrd3b3svuLiYi1YsEBBQUG1EhIAAAA1a2J0hMbPiZVhSKapsts3b+whLzdnzd10SIt3pighNUsvLdytfy/arQERgbq2V0sN6Rwsdxcne78FAADg4KpdSjVp0kSGYcgwDHXo0KHC/YZhaOrUqTUaDgAAALUjJipUM0f31IzlCUpMy1bbQC9NGNxBMVEhkqSBHQKVkVeon7Yd0dxNh7Rx/wn9Gp+mX+PT5OPurBHnNdfIXi3Us1VTLd6ZounLEriKHwAAsEm1S6kVK1bINE1deumlmjt3rpo1a1Z2n6urq1q3bq3mzZvXSkgAAADUvJio0L8tj3zdXXRjn1a6sU8rJaVna17sIc2LTVbyyVx9uf6Avlx/QEE+bkrNzJehks3SuYofAACormqXUgMHDpQkJSUlqVWrVjKMynYhAAAAQEMUHuClyUM66oHoDvo96Zi+3XRIC7enKDUzX9L/rt5nSjIkzVieQCkFAAD+ls0bnf/888/69ttvK4x/8803mj17do2EAgAAQP1ksRjq1y5Ar1/XXRueiJazpeL/qDQl7U7J1H82HNSpnMK6DwkAAByCzaXUiy++qICAgArjQUFBeuGFF2okFAAAAOo/bzdntQ/yrvQqfqYpPTx3m3o/v1S3z96g77ckKyu/qM4zAgCA+qvay/dKHThwQOHh4RXGW7durQMHDtRIKAAAADiGqq7id1W3UO1OyVLc0Uwt25WqZbtS5eZs0eBOQRpxXnNdGhnEFfwAAGjkbC6lgoKCtG3bNrVp06bc+NatW+Xv719TuQAAAOAAznQVv/ijmfpx62H9d9sRJaVna8H2FC3YniIvVydd1jlYV3RrrgERgfp591Gu4AcAQCNjcyl144036v7775ePj48uvvhiSdKvv/6qCRMm6IYbbqjxgAAAAKjf/u4qfh2CfTRpSEc9cFkH7Tycof9uO6wftx5R8slcfbflsL7bclgeLhblFlq5gh8AAI2MzaXUc889p3379mnw4MFydi55utVq1c0338yeUgAAAKiUYRiKauGnqBZ+mhITqdgDJ/XjtsP6aduRKq/gN30ZV/ADAKAhs7mUcnV11ddff63nnntOW7dulYeHh7p27arWrVvXRj4AAAA0MIZhqFfrpurVuqmeuLyzIp9cqMJis9xjSq/g9685mzSkS7Au7RgsP08X+wQGAAC1wuZSqlSHDh3UoUOHmswCAACARsbJYqhdoLfiUjJlVnL/wh0pWrgjRc4WQxe09dfQLsG6rHOIQvzc6zwrAACoWdUqpSZNmqTnnntOXl5emjRp0t8+9vXXX6+RYAAAAGgcqrqC32PDIpWZX6TFO1MUfzRLq/eka/WedD35/U51D2uiIV2CNbRLiNoFekuSFu04wmbpAAA4kGqVUps3b1ZhYWHZn6tiGEbNpAIAAECjcaYr+E0e0lFJ6dlasjNFi3emKPbASW05WPLx70Vxah/krXaBXlq88yibpQMA4ECqVUqtWLGi0j8DAAAANeHvruAnSeEBXrprYDvdNbCdUjPytHTXUS3eeVRr96ZrT2qW9qRmSTpts3RDmrGczdIBAKivznpPKQAAAMAegnzdNapva43q21oZeYVasTtVD3y9RdbTNqUyzZIZU5+t3adBHYMU1szTPoEBAEClqlVKXXPNNdU+4Lx58846DAAAAGALX3cXXdW9hd77ZW+lm6VbTenJ73dK2qmIIG9dEhmkQR0D1bt1M7k6W+wRGQAA/KlapZSfn1/Zn03T1Pz58+Xn56fevXtLkjZt2qSTJ0/aVF4BAAAANaWqzdL/0aOFkk/matP+E0pIzVJCapY+WJkobzdnXdQ+QJf+WVIF+f7van5smA4AQN2oVin1ySeflP35kUce0XXXXaeZM2fKyclJklRcXKy7775bvr6+tZMSAAAA+Btn2iz9VE6hVu1J04rdafo1PlXpWQVatDNFi3amSJK6NPfVJR2D5OHqpFcWx7FhOgAAdcDmPaU+/vhjrV69uqyQkiQnJydNmjRJ/fr10yuvvFKjAQEAAIDq+LvN0v08XTTivOYacV5zWa2mtief0oq4VK2IS9O2Qye183CGdh7OKHs8G6YDAFD7bC6lioqKtHv3bnXs2LHc+O7du2W1WmssGAAAAFAbLBZD3cKaqFtYE02M7qD0rHz9GpemFXGp+nHbkQqPN00pPiVTy3cdVd+2/vJ241pBAADUBJv/izpu3Djddttt2rt3r/r06SNJWrdunV566SWNGzeuxgMCAAAAtSnA203X9mqpa3u1VELqSsVXsmF6sSndNnujnC2Guoc10UURAbqofYC6hTWRixMbpgMAcDZsLqVeffVVhYSE6LXXXtORIyX/Jyk0NFQPPfSQJk+eXOMBAQAAgLrywOkbpqtkCd+AiAAdOJ6j/cdytHH/CW3cf0LTlyXI281ZF7RtpovaB+iiiAC1C/SWYRhslg4AQDXYXEpZLBY9/PDDevjhh5WRUbLung3OAQAA0BCcacP0g8dztHpPulYnpOu3vek6mVOoZbtStWxXqiQpxNddbfy99HvSMTZLBwDgDM5qQXxRUZF++eUX7d27VzfddJMk6fDhw/L19ZW3t3eNBgQAAADq0t9tmB7WzFM39mmlG/u0ktVqaufhjJKSak+aNuw7oZSMPKVk5Ek6bbN0Sa8tiaeUAgDgL2wupfbv36+YmBgdOHBA+fn5uuyyy+Tj46OXX35Z+fn5mjlzZm3kBAAAAOoVi8VQ15Z+6trST/8a1E55hcXauO+Exn68XsVm+V2pTEkJqVm69LVf1DfcXxe0baa+4f4K8XO3T3gAAOoBm0upCRMmqHfv3tq6dav8/f3Lxv/xj3/ojjvuqNFwAAAAgKNwd3HSRREBigj2Vlwlm6VLUmJathLTsvXl+gOSpNb+nuob3kwXtPVX37b+atHEo+yx7EsFAGjobC6lVq1apTVr1sjV1bXceJs2bZScnFxjwQAAAABHNPH0zdL/vH39um7ycXfRusRj+j3pmP44nKH9x0o2T//PxkOSpJZNPdQ33F+ebk76bO1+9qUCADRoNpdSVqtVxcXFFcYPHTokHx+fGgkFAAAAOKozbZZ+WedgSVJGXqE27juudYnH9XvSce1IPqVDJ3J16MShsmOdvi/V9GUJlFIAgAbD5lJqyJAhmj59uj744ANJkmEYysrK0tNPP63hw4fXeEAAAADA0fzdZumlfN1ddGlksC6NLCmpsvKLtGn/Ca1LPKb3ftlbYfmfKWl3SqbG/N869WzVVL3bNFX3sCbycXepnTcBAEAts7mUevXVVxUTE6POnTsrLy9PN910kxISEhQQEKAvv/yyNjICAAAADZ63m7MGdgjUwA6B+nl3apX7Uq1KSNeqhHRJJUsDOwb7qHebpurVuql6tWqmsGYeMgyj7PHsTQUAqK9sLqXCwsK0detWff3119q6dauysrJ02223adSoUfLw8DjzAQAAAAD8rar2pXri8k5yc3HSpn3HtenACR08nqvdKZnanZKpOb+XbJ4e6OOmXn/OpCoosurfi+PYmwoAUC/ZVEoVFhYqMjJSP/74o0aNGqVRo0bVVi4AAACg0TrTvlRjLmgtSUrNyNOm/Se0af8Jbdx/QjsPn1JaZr4W7UzRop0pZcc7fW+qGexNBQCoB2wqpVxcXJSXl1dbWSqVnJysRx55RAsXLlROTo7at2+vTz75RL17967THAAAAEBdqs6+VEG+7hrWNVTDupY8Lq+wWNuTT2njvpKiatmuoxWeY0ralZKp22ZtULewJiUfLf3UxNO1wmMBAKhNNi/fu+eee/Tyyy/ro48+krOzzU+3yYkTJ9S/f39dcsklWrhwoQIDA5WQkKCmTZvW6usCAAAAjsjdxUnnt2mm89s0kyTFTF9Z5d5Uy3enavnu1LLP2/h7qltYE3X/s6jqHOordxcnSexLBQCoHTa3Shs2bNDy5cu1ZMkSde3aVV5eXuXunzdvXo2Fe/nllxUWFqZPPvmkbCw8PLzGjg8AAAA0ZFXtTfVwTEd5uDhp68GT2nrolJLSs7XvWI72HcvR91sOS5KcLYY6hfqqqZeLVsansy8VAKDG2VxKNWnSRNdee21tZKnghx9+0NChQ/XPf/5Tv/76q1q0aKG7775bd9xxR528PgAAAODIzrQ3VamTOQXadujUnyXVSW05eFLpWQXannyq7DHmabdT//uHwgO81S7QS85Olrp5QwCABsXmUuqvs5ZqW2Jiot577z1NmjRJjz32mDZs2KD7779frq6uGjt2bKXPyc/PV35+ftnnGRkZkko2aS8sLKyT3LWlNL+jvw80HpyzcDScs3A0nLOojsEdAzS4Y0C5sdPPGS8XQxeGN9GF4U0kSaZp6vCpPG07dEoP/GebiitZ/3fkVJ6GTl8pN2eLIkN8FNXcV12a+6hzqK8igrzl6ly+qFq886je/HmPEtOc9M7e33T/pe01tEtwjb5XoKbxcxaOpr6cs9V9fcM0zcqWmFdgtVr1yiuv6IcfflBBQYEGDx6sp59+Wh4eHucU9O+4urqqd+/eWrNmTdnY/fffrw0bNmjt2rWVPueZZ57R1KlTK4x/8cUX8vT0rLWsAAAAQEP08lYnHc6RSq7bV8qUq6VkOWB+sVHhOU6GqeaeUksvUy29TOUVSf896KT/Xf+v5PbWDsXq5l+tX0cAAA4kJydHN910k06dOiVfX98qH1ftmVLPP/+8nnnmGUVHR8vDw0MzZsxQamqqPv744xoJXJnQ0FB17ty53FinTp00d+7cKp/z6KOPatKkSWWfZ2RkKCwsTEOGDPnbL4QjKCws1NKlS3XZZZfJxcXF3nGAM+KchaPhnIWj4ZxFXXBqfVT3frX1tH2pDL1xfTdFRwbpwIkc7UjO0M4jmfrjcIZ2HsnQqdwiHcyWDmafXlgZZbeGpFUnffXomP51/I6A6uPnLBxNfTlnS1etnUm1S6lPP/1U7777ru666y5J0rJly3T55Zfro48+ksVSO2vI+/fvr7i4uHJj8fHxat26dZXPcXNzk5ubW4VxFxeXBvNDpCG9FzQOnLNwNJyzcDScs6hNI7q3lLOzU5X7UkWEuCoipIn+8efjTdPUoRO52pF8SjsOn9L25AytjE+rcFxTUkJqtga8slKdQn3UKdT3zw8fhQd4y8lScQYWYC/8nIWjsfc5W93XrnYpdeDAAQ0fPrzs8+joaBmGocOHD6tly5a2J6yGBx54QP369dMLL7yg6667TuvXr9cHH3ygDz74oFZeDwAAAEBFMVGh1b7SnmEYCmvmqbBmnhrWteQ5MdNXKi4lU5Ut1EvJyFNKRp5WxP2vuHJztqhjiI86hfiWFVaRob5auzdd05clKCk9W+EBXpoYHcEVAAHAgVW7lCoqKpK7u3u5MRcXl1rdPOv888/X/Pnz9eijj+rZZ59VeHi4pk+frlGjRtXaawIAAACoWROjIzR+TuxpSwCl6dd3U8umntp1JEN/HMnUriMZikvJVG5hsbYdOqVth05Vecy4lEyNnxOrt2/qoRHnNa/DdwMAqCnVLqVM09Qtt9xSbmlcXl6exo8fLy8vr7KxefPm1WjAESNGaMSIETV6TAAAAAB1JyYqVDNH99T0ZfHaczRT7YN9NDG6Y9kSwN5tmpU91mo1tf94jnYdyfjLR6aST+aWO2bprKt7v9ist3/eow7BPuoY4lNyG+yjlk09ZGEJIADUa9UupcaOHVthbPTo0TUaBgAAAEDDFBMVqsEdA7RgwQINH96vyv1GLBZD4QFeCg/w0vCu/1ua1+HxhSootlb6nN0pmdqdkilt/d+Yh4uTOgR7ly+rQnwU5OOmxTtTWAYIAPVAtUupTz75pDZzAAAAAECV2gZ6VdiXyjCkdoFeemx4J8WlZCn+aKbiUjK1Jy1LuYXF2nrolLaetgTQw8Wi3ML/lVulywDfG9WzbA8sAEDdqHYpBQAAAAD2UtW+VA8OidSlkcG6NDK47LFFxVbtP56j+JRMxR3NLCur9h3LKVdISf9bBnjPF7HqFtZEEUHeav/nR0SQj1o0qXwZ4KIdR5htBQDniFIKAAAAQL1Xui/VjOUJSkzLVttAL00Y3KFsX6q/cnayqF2gt9oFepeb/ZRXWKyuzyxWYXHF6wBaTWnzgZPafOBkuXF3l5JjtQ/yVvtAb0UEe+vIqTxN/e8fMlRSapXOtpo5uifFFADYgFIKAAAAgEOIiQo9p9LH3cVJ7QK9K10GGO7vpUlDOmhPapYSUrO0NzVLiWnZyiu0aufhDO08nFHheOZfbg1JLy3crQvbBsjPs/L9sgAA5VFKAQAAAGg0qloG+HBMZIVZV0XFVh08kauEoyX7VO1JLfnYdto+VVJJMbXvWI66PbtE/l6uahvopbYB3iW3gSW3rZp5ysXJUvYclgACaOwopQAAAAA0GrYuAyy9EuCQvx5j+soKs60kydliqMhq6lh2gY5lF2jDvhMV7m/VzFNtA71kGIaW/nGUJYAAGjVKKQAAAACNyrkuA6xqttXbN/XUgIgAJaVna29alvamZSsxrWQZYFJ6tnILi5WYnq3E9OyyY5mn3T707TbtPJyhNv5eahPgqTb+Xmrm5SrDqLjZeilmXAFwVJRSAAAAAGCDM822imrhp6gWfuWeY7WaSsnIU2JathLTs/TMDztlrbjfujLzivTWz3vKjfm4Oys8wEut/b0U7u+pNqV/DvDSusRj+tfnscy4AuCQKKUAAAAAwEa2zrayWAw1b+Kh5k08dFFEgL5Yd6DihuuSAn3cNLhTsPalZ2v/sWwdPpWnzLwibTt0qtK9rCx/TqA6fdP1V5fEa0jnEFksVc+wAgB7o5QCAAAAgDpW1RLAZ6+KKre/VV5hsfYfy9G+Y9nal579523J50dO5VU628qUtCc1S5FPLVLLph5q3cxTrZp5KuzP21b+Jbeerv/7dZAlgADsgVIKAAAAAOpYdTdcd3dxUscQH3UM8alwjNyCYg1/c5X2pWdX2HRdkgqKrCXLBdOyK7lXCvB2U6tmHnK2GFr/l03ZWQIIoK5QSgEAAACAHZzrhuserk56JKZjpTOu3r2ph7q2bKIDx3PKfRw8nqP9x3J0KrdQ6Vn5Ss/Kr3Dc0oLr3i82q0erJLVo4qEWTT3Uoonnn7clHx6uTuWex2wrALailAIAAAAAB3WmGVdhzTzVv5Lnncop1METJUXVfV9uVnEl6wCLrKY27DuhDTpRyREkfy/XspKqoMiq5btT2XAdgE0opQAAAADAgZ3NjCs/Txf5eZZcJfDN5QmVbrre2t9Tk4d0VPLJXCWfyC13m5VfpGPZBTqWXVBuA3bztNt7v9isbmFJCvZ1U7Cvu0J83RXi564gn5LbEF93ZlwBjRilFAAAAAA0YlVtuj5lWKcKe1xJkmmaysgt0qGTOWUl1bQfd6nYrHy21ab9lc+0KuXj7lxWVhUVm1qbeKzsvtIZV/8eeZ6u7dlSTtW8miDFFuAYKKUAAAAAoBGr7qbrpQzDKJtp1aW5nyTp6w0Hq5xt9XBMpI5m5CklI09HT+XpaEZ+2ec5BcXKzCtSZl6WElKzKrxW6fEe/nabHpm7TU08XNTMy1X+Xm5q5uWqZt6uaubpWjLmXXK760iGXliw+5yXEi7acURvLI3X3lQnvZu4Rg9c1oFiC6hhlFIAAAAA0Mid66brts62kkpmXGXmFyk1I08pp/KVkpGnR+Zuq3R/q5LHSydyCnUip1B7q7iiYLnHn3Y74ast6tZyn7zcnOTl5izvPz+8/nLr5eYkbzdn7TycodeXxv9ZbBmKP5p11ntkMWsLqBqlFAAAAADgnNg620oqmXHl6+4iX3cXtQ/ykSR9tCqx4owrQ+oY7KPPbuur49kFOpadr+PZBSV/zir435+z83Uiu1BxRzMrfb38IqvW7ztu0/uqbI+s8IB4+Xm4yM/DRb6lt+7O8v3L5yVjLtp88IQen7+DDeCBKlBKAQAAAADO2bnOtpKqnnE1MbqDAn3cFOjjJsnn73NMX1npUsKWzTz0SEyksvOLlJVfrOz8oj//XFR+rKBI2w+dUmXztYqsZqXLDM/kr+WWYUgzlidQSgGilAIAAAAA1BNnM+PqdFUVW48P71zt41RVbLUJ8NLzV0fpVG6hMvIKdSq35CMjt6jSsfSs/ArHNk0psRrLD4HGgFIKAAAAAFBvnOuMq9osth6JiVS/9gHVz1JJuSVJLk4WJZ/MVYsmHtU+FtAQUUoBAAAAABqUmiq2pi+L156jmWof7KOJ0R1tKrakiuVWqaz8IkW/9qseuCxC4/qHy8XJctZZAUfGmQ8AAAAAwGliokL133v66bULivXfe/rZXEiVHmPm6J6KDPGRm7NFnUJ99PQVndWnTTPlFhbrhQW7dcVbqxV74EQtvAOg/mOmFAAAAAAAtaSyWVu39GujbzYd0osLdml3SqaufW+NburTSg/HRMrPw8VOSYG6x0wpAAAAAADqkGEYuq53mJZPHqSRvVrKNKXP1x3Q4Nd+1fdbkmWalV37D2h4KKUAAAAAALCDZl6uevWf3fTVnReoXaCX0rPyNeGrLbr54/Xal84V+tDwUUoBAAAAAGBHF7T114IJA/TgkA5yc7ZoVUK6hkxfqTeXJyi/qNje8YBaw55SAAAAAADYmZuzk+69NEJXdGuuJ77boVUJ6Xp9aby+25Ksq7q10MIdR5SUnq3wAC9NjI44p6sLAvUFM6UAAAAAAKgnWvt76dNb++jNG3sowNtNiWnZemNZvHanZCq/yKq4lEyNnxOrRTuO2DsqcM4opQAAAAAAqEcMw9CV3Zpr+eSBauJZ/mp8piTDkGYsT7BPOKAGUUoBAAAAAFAP+Xm4KLeg4p5SpiklprEROhwfpRQAAAAAAPVUeICXjErGmzfxqPMsQE2jlAIAAAAAoJ6aGB1RtmTvr46czNWGfcftkgmoKZRSAAAAAADUUzFRoZo5uqciQ3zk5mxRx2AfdQj2Vl6RVWP+b51WJaTZOyJw1pztHQAAAAAAAFQtJipUMVGhZZ/nFRZr/JxN+iUuTbfN2qi3b+qhIV1C7JgQODvMlAIAAAAAwIG4uzjpgzG9NSwqRAXFVv3r81h9vyXZ3rEAm1FKAQAAAADgYFydLXrrxh66pmcLFVtNTfx6i75cf8DesQCbUEoBAAAAAOCAnJ0senVkN425oLVMU3p03nb93+oke8cCqo1SCgAAAAAAB2WxGHr2qi66a2BbSdJzP/6hN5cnyDRNOycDzoxSCgAAAAAAB2YYhqbEROrBIR0kSa8vjddLC3dTTKHeo5QCAAAAAMDBGYahey+N0JMjOkuS3l+ZqCe/3yGrlWIK9RelFAAAAAAADcRtF4XrpWu6yjCkOb8f0IPfbFVRsdXesYBKUUoBAAAAANCA3NCnlaZf311OFkPzNifrvi83q6CIYgr1j7O9AwAAAAAAgJp1VfcW8nBx0r1fbNbCHSna/85vKraa2ncsW+EBXpoYHaGYqFB7x0Qjx0wpAAAAAAAaoCFdQvR/t/SWq5NFfxzJUNzRTOUXWRWXkqnxc2K1aMcRe0dEI0cpBQAAAABAAzUgIlChfu7lxkxJhiHNWJ5gn1DAnyilAAAAAABowFIy8iqMmaaUmJZthzTA/1BKAQAAAADQgIUHeMmoZLx5E486zwL8FaUUAAAAAAAN2MToiLIle3+VfDJXv8Sl2iUTIFFKAQAAAADQoMVEhWrm6J6KDPGRm7NFHYO91SnURwVFVt02e6O+2XjQ3hHRSDnbOwAAAAAAAKhdMVGhiokKLfu8oMiqKXO3ad7mZD307TalnMrTvZe2l3H6dCqgFjFTCgAAAACARsbV2aLXruumuwe1kyS9tjRej83foaJiq52ToTGhlAIAAAAAoBEyDEMPx0Tquau6yDCkL9cf0Pg5m5RbUGzvaGgkKKUAAAAAAGjExlzYRu+N6iU3Z4uW7UrVjR/+rmNZ+faOhUaAUgoAAAAAgEYuJipEX9zRV008XbTl4EmNnLlWB47l2DsWGjhKKQDA/7d372FV1Xnfxz8LNoKAYBwET3mKPCAqamaWqYkOpmU6aZNak3WXh0ZDq2dqJrUyze5KpbxnLGuqqSxtymeeuk3Fc2qm5oTiOZDJEyqSgScOe6/nD4adhplZ7rV/8H5dV5eyXG6/zHyu5d4ff+u3AAAAAHVoFKV/jOyi+rVram/+SQ3861pt3f+d02OhCqOUAgAAAAAAkqSr6oRrwegualU3QvknSnTHq59r5a4jTo+FKopSCgAAAAAAeNWJCNG8EZ3VNSFGp0rcuu+tTfpg0z6nx0IVRCkFAAAAAADOUSskSK///hoNTK4vt8fWo//YopeX7ZFt206PhirE5fQAAAAAAADA/9RwBejFwW0VHxmiv6zM1osZu/X6mr06VepW05gwpaUkKLV1XafHhMFYKQUAAAAAAM7Lsiz9n9QW+t01DSVJx0+XqqTMo115RRr5zmYtyjrk8IQwGaUUAAAAAAC4oK/2HZd11te2JEtS+rI9Dk2EqoBSCgAAAAAAXNDe/JP64W5StqSvj5xwYhxUEZRSAAAAAADggprEhJ2zUqpCqdvWK6uy2QAdl4RSCgAAAAAAXFBaSkL5LXv/aaassxqqZz/dqbHvf6VTJWWOzAZzUUoBAAAAAIALSm1dV7OHtVeL+FoKdgWoRXwtzR7WXpP7J8oVYOnjzIMa+Jd12ldwyulRYRCX0wMAAAAAAAD/l9q6rlJb1610vEXdCI16Z7N25hXplllr9PKdyeqaEOvAhDCNUSulpk2bJsuylJaW5vQoAAAAAABA0jWNo/TxmOvVtmFtHT9Vqt//bQP7TOGiGFNKbdy4Ua+88oratGnj9CgAAAAAAOAsdSNrat4DnTW4YwN5bPaZwsUxopQ6ceKEhg4dqjlz5uiKK65wehwAAAAAAPADIUGBeu63bdhnChfNiD2lHnzwQfXt21cpKSl65plnLnhucXGxiouLvV8XFhZKkkpLS1VaWnpZ57zcKuY3/ftA9UFmYRoyC9OQWZiGzMI0ZPbS/K5jfV0VG6ox72eW7zP18hrNGNxGN1wV7fRoVZ6/ZPZi/3zL9vObPN9//31NmTJFGzduVEhIiLp376527dpp5syZ5z3/ySef1FNPPVXp+Ny5cxUaGnqZpwUAAAAAAJJ0vFj62+5A/fuEJUu2brnSo5vq2bIspyfD5Xbq1CkNGTJE3333nSIiIn70PL8upfbt26eOHTsqIyPDu5fUT5VS51sp1bBhQ+Xn51/wfwgTlJaWKiMjQ7169VJQUJDT4wA/iczCNGQWpiGzMA2ZhWnI7C9XXOrWpE926MPNByVJfZPidVPzGL36Wa72HjulJtGhGtOjmX6TGOfwpFWDv2S2sLBQMTExP1lK+fXte19++aWOHDmi9u3be4+53W6tXr1as2bNUnFxsQIDA8/5PcHBwQoODq70WkFBQVXmIlKVvhdUD2QWpiGzMA2ZhWnILExDZi9dUFCQXhjUTu0aXqGnPt6u/92ap//dmidLki1p9+ET+sP7mZo9rL1SW9d1etwqw+nMXuyf7delVM+ePbV169Zzjg0fPlwtWrTQH//4x0qFFAAAAAAA8C+WZemu6xqreXyE7pzzudye8kJKKv/RsqT0ZXsopaohvy6latWqpdatW59zLCwsTNHR0ZWOAwAAAAAA/9WpSZQCrQC55TnnuG1LOUdPOjQVnBTg9AAAAAAAAKB6aBobpvPtcx4fGeLzWeA840qplStX/ugm5wAAAAAAwH+lpSR4b9k727+PndLUhTt0ptTtyFxwhnGlFAAAAAAAMFNq67qaPay9WsTXUrArQFfHhatL02hJ0qurc3TrrDXKOvCdw1PCV/x6TykAAAAAAFC1pLauW2lT84zth/X4R1u0+/AJ3fY/azXmpgSN7tFMQYGspanK+H8XAAAAAAA4qlerOC0Z1003J8WrzGNrxtLd+u1f1+nrI0VOj4bLiFIKAAAAAAA4Liqshv5nSHul/66dIkJc2rL/O/V9aY1e+yxHHo/t9Hi4DCilAAAAAACAX7AsS/3b1deScd3U7epYFZd59Mz/7tCdc9ZrX8Epp8fDr4xSCgAAAAAA+JX4yBC9OfwaTRnQWqE1AvXF3gKlzlyt9zd8I9tm1VRVwUbnAAAAAADA71iWpaHXNtINV8XokQ8ytTH3Wz320VYt2X5Yv2kVpzfW5Wpv/kk1iQlTWkpCpc3T4f9YKQUAAAAAAPxWo+gwvf/AdfrzzS1VwxWg5TuP6I8fbdWuvCIVl3m0K69II9/ZrEVZh5weFT8TpRQAAAAAAPBrgQGW7r+xqT4Zc4OCXeVVRsVNfLYky5LSl+1xbD5cGkopAAAAAABghKvjaul8O0rZtpR95KTP58EvQykFAAAAAACM0TQmTNZ5jpd5PJq5dLdOFJf5fCZcGkopAAAAAABgjLSUBO8te5K8BZXHlmYu3aPuz6/QW+tyVVLmcWpEXCRKKQAAAAAAYIzU1nU1e1h7tYivpWBXgFrUraW/Dm2vWUOS1Tg6VPknSjTp/21TyvRV+n+ZB+XxnO+GP/gDl9MDAAAAAAAA/BypresqtXXdSsd/kxiv9zfuU/rSPfqm4JTGvvcvvbIqW4/1aaGuCbEOTIoLYaUUAAAAAACoEoICA3RX50Za9Wh3PdzraoUHu7TtYKHuen2Dhr62Xlv2H3d6RJyFUgoAAAAAAFQpYcEujemZoFWPdte91zdRjcAArf36mG6dtVZ/mLtZufk8qc8fcPseAAAAAACokqLDgzXxllYafn1jzcjYrQVfHdAnWw5pUVaerr8qRgeOn9a+glNqEhOmtJSE894SiMuHlVIAAAAAAKBKaxgVqul3tNPCsV3Vo3msyjy2Vu0+qq+PnFBxmUe78oo08p3NWpR1yOlRqxVKKQAAAAAAUC20rBuhN4Z30pVRoeccr3g+3xP/N0tZB76TbfPEPl/g9j0AAAAAAFCtHC48c97j+SdK1O/lNapfu6Z6tYpT78Q4dWocJVcga3ouB0opAAAAAABQrTSJCdOuvCKdvR7KkhQe4lKZ29aB46f15rpcvbkuV7VDg9SzRXlBdWNCrGrWCHRq7CqHUgoAAAAAAFQraSkJGvnOZlmWZNvy/vj87W3VvXms1uzJ1+JteVq647C+PVWqDzfv14eb9yskKEA3JsTqN4nx6tmyjmqH1tCirEOauXSP9uafvOQN03+N1zARpRQAAAAAAKhWUlvX1exh7ZW+bI9yjp5U09gwPdTzaqW2jpckpbSKU0qrOJW5Pdr072+1ZNthLd6WpwPHT2vJ9sNasv2wAgMsXRUbpl2HT8hS+b5UFRumP/fbJHVNiFWZ21apx1P+o9ujMo+tMrdHpW5bZf85/sXeY5q9Ksc7W8VrzB7WvsoXU5RSAAAAAACg2kltXfcnSx9XYIA6N41W56bRmtCvpbYdLCwvpbblaWdekXYdPiHp+43SK37844dbL3kuW+Urt9KX7aGUAgAAAAAAqO4sy1Lr+pFqXT9S43tdrX8fO6mbXlwlt+f8T+qrERggV6AlV4ClIO/PAxQUaMkVGOA9nnXgO/3wFWxbyjl68vJ/Uw6jlAIAAAAAAPiZGkWHKaFOeOUN0y2pRXwtffrQjRf1OqkzV5/3NZrGhv2q8/ojnmkIAAAAAABwCdJSEry320nfb5j+UM+rffoapqKUAgAAAAAAuAQVG6a3iK+lYFeAWsTX0uxhHbwbpvvqNUzF7XsAAAAAAACX6GI2TPfFa5iIlVIAAAAAAADwOUopAAAAAAAA+BylFAAAAAAAAHyOUgoAAAAAAAA+RykFAAAAAAAAn6OUAgAAAAAAgM9RSgEAAAAAAMDnKKUAAAAAAADgc5RSAAAAAAAA8DlKKQAAAAAAAPgcpRQAAAAAAAB8jlIKAAAAAAAAPkcpBQAAAAAAAJ+jlAIAAAAAAIDPUUoBAAAAAADA51xOD3C52bYtSSosLHR4kl+utLRUp06dUmFhoYKCgpweB/hJZBamIbMwDZmFacgsTENmYRp/yWxFB1PRyfyYKl9KFRUVSZIaNmzo8CQAAAAAAADVR1FRkSIjI3/01y37p2orw3k8Hh08eFC1atWSZVlOj/OLFBYWqmHDhtq3b58iIiKcHgf4SWQWpiGzMA2ZhWnILExDZmEaf8msbdsqKipSvXr1FBDw4ztHVfmVUgEBAWrQoIHTY/yqIiIiuCDCKGQWpiGzMA2ZhWnILExDZmEaf8jshVZIVWCjcwAAAAAAAPgcpRQAAAAAAAB8jlLKIMHBwZo0aZKCg4OdHgW4KGQWpiGzMA2ZhWnILExDZmEa0zJb5Tc6BwAAAAAAgP9hpRQAAAAAAAB8jlIKAAAAAAAAPkcpBQAAAAAAAJ+jlAIAAAAAAIDPUUoBAAAAAADA51xODwDfOHr0qIqKilRUVKS2bds6PQ7wk/Ly8nTw4EEVFRXp2muvVUhIiNMjARfEdRamIbMwDZmFacgsTONEZlkpVQ1s2bJFXbp0Ub9+/ZScnKwBAwZowYIFTo8F/KgtW7aoU6dOuueee9SjRw/16dNHM2fOdHos4EdxnYVpyCxMQ2ZhGjIL0ziVWUqpKi4vL0+33nqrBg4cqLlz52rdunUqKCjQiy++qBdeeMHp8YBKjh07pkGDBumOO+7QJ598oh07dujKK6/UO++8o7Fjxzo9HlAJ11mYhszCNGQWpiGzMI2TmaWUquJ27typ4OBgjRs3Tu3atVPnzp317rvvKjExUf/4xz/0l7/8xekRgXPs379fHo9H999/v6688ko1b95cL7zwgm6//XatWrVKjz32mNMjAufgOgvTkFmYhszCNGQWpnEys5RSVVzNmjV14sQJ5ebmSpLcbrcaNGigp556SldffbXmz5+v7du3OzskcJbw8HCdOXNGW7ZskSTZtq3Y2FiNHDlSAwYM0PLly7V48WKHpwS+x3UWpiGzMA2ZhWnILEzjZGYppaq4Bg0aKDAwUPPnz5ckBQYGyu12Kz4+XlOnTtW2bdu4txl+JSoqSo0bN9ZHH32kb7/9VpZlSZJq166tsWPH6vTp0/r0008dnhL4HtdZmKZ+/fpkFkZp2LAhmYVRyCxM4+T7WUqpKubkyZM6duyYysrKVFZWpvr16+vFF19Uenq6d6PogIAA2batBg0a6Oabb1ZWVpazQ6Na83g83p/btq0rrrhC06ZN0wcffKApU6bo1KlT3l+PiopSamqqtm3bJrfb7cS4gEpKSnT69Gnv1/Xr19eMGTO4zsJvFRYWKjc3V0eOHNGZM2fUoEEDTZ8+nczCb2VnZ+uDDz7wfl2vXj3NnDmTzMJvffnllxo3bpyk8ve2ZBb+zp96A9dleVU4IisrSyNHjtS3336r4OBgpaamatSoURo0aJCys7M1fvx4nT59Wg899JBCQ0MlScePH1fjxo2dHRzVVk5OjpYuXaqBAwcqJiZGUvlS0euvv17vvvuuhg4dqtOnT2v8+PFq1qyZJOnAgQOqV6+edwUV4Es7duzQhAkTtG/fPoWGhurRRx9VSkqKfvvb3+q5557Tww8/zHUWfiUrK0ujRo3S0aNHFRAQoAceeECjR4/W7bffTmbhl44fP65OnTopMjJSBQUFGjFihCRpwIABZBZ+KTMzU127dtX9998vqfyDvCQNHDhQ06ZNI7PwO/7WG1BKVRG5ubnq3r277rjjDvXq1UvLly/XqlWrtGjRIn344Yd67LHHFBYWpvHjx2v9+vWKjo6Wy+XS8uXL9cUXXzg9PqqhPXv26JprrpFt2yopKdGQIUMUFRXlbeQHDx6s8PBwDR06VNu3b1dwcLBiYmL08ccfa926dd6/8AFf2b59u7p166aBAweqe/fu+uijjzR+/HitXLlS8fHx+sMf/qDw8HCNHTuW6yz8wrZt29StWzfdfffdGjBggN5++2399a9/1fDhw1WjRg099NBDqlmzptLS0sgs/EZxcbHCw8PVoUMHzZ07V5I0YsQIWZal0aNHKywsjOss/EZmZqauv/56Pfjgg3r++ecr/fqjjz6q0NBQrrPwG/7YG1i2bduX5ZXhU3PnztWrr76qjIwMBQUFSZKWLVumadOm6ZtvvtHixYvVuHFjrV+/Xm+88Yb279+vmJgYPfLII0pKSnJ4elQ3hYWFGj58uMLCwhQSEqKMjAyNGzdOw4YNU1RUlKTypc8BAQHavn27Fi5cqC+//FL16tXTvffeq8TERIe/A1Q3+fn5GjhwoNq1a6eXXnrJe7xRo0YaOXKkHn/8ce+xjRs36rXXXuM6C0cdPnxYN998s7p166bp06dLKn/c8913363//u//VkxMjCIjI1WrVi19/vnnevPNN8ks/MYdd9yhfv36aeXKlcrKytKIESN07733aufOnWrRooU2bNig119/nczCUQcPHlSzZs10991365VXXlFxcbGeeeYZZWdnq6ioSIMGDVK/fv0UFRXFZzD4DX/sDVgpVUUcO3ZMW7Zs0ZkzZ7zh6tmzp2rWrKlJkyZp9OjReuutt9S5c2d17NhRLpdLpaWl3nMBXyotLVWHDh3UsmVLDRgwQOPHj9eMGTMkyVtMWZYlj8ejVq1aqWXLlt6vWSEFJ+zcuVOhoaG69957JZX/S35wcLCuueYanTlzxnuex+PRNddco3bt2ikoKIjrLBxz6NAhDRgwQHfeeaf32OzZs7VmzRoNGDBAERERqlu3rubMmaPrrrtOHTt2JLNwnNvtVmBgoAoKChQaGqrJkydr0qRJevPNN73l6oYNG9SpUye1b9+e97Nw1L59+9S2bVtt3rxZBw4c0AMPPKDjx4+rZcuWOnLkiKZPn64vvvhCkydP5jMY/IY/9gZ8uqsiOnfurEaNGmnBggUqLS31Hr/uuuv0+9//Xt98842ys7MlybsXj8tFJwlnREdH67777lP//v0lSdOnT9dtt92mGTNm6O2331ZBQYEsy5Lb7VZhYaE3sxRScErnzp11++23q127dpK+v35GR0ersLDQe15AQIBKSkq8f3FznYVT2rZtq7vuusu7H99LL72kp59+WnPmzFFGRob+/Oc/q6CgQPPnz5dt297rK5mFkypymJqaqszMTNWrV09TpkzRoUOHlJubq379+nn3N6lAZuGUa6+9Vunp6QoNDVXDhg0lSf/85z/12muvaenSpRo8eLCWLFni/QzGdRb+wB97Az7hVRHJyclq1KiRZs6cqY0bN3qfaGZZloYNG6aCggJlZGRIKn+8Y8WvAU6Ji4tTQECA92I4Y8YM3XbbbZo5c6beeecd5eXl6YknntDo0aN50h4c5Xa75XK59F//9V+Syp8SWXEdLSkpUX5+vvfcl19+Wa+//roq7oznOgsn2LYty7LUqFEj77EePXpoxYoVGjp0qK666ioNHjxYZWVl2r17tyzL4r0B/EJF/sLCwrRmzRpJ0p/+9CcVFhaqZ8+e+vzzz5Weni7p+w9JZBZOqPh7/tprr9UzzzyjsWPHavz48YqJifG+b/3Tn/6kgwcPau3atZK+L6XILJzkj70BpZTBKi54FR+Y3nvvPZWUlGjUqFFavny592LpdrvVqlUr1atXz8lxgfOWS0FBQd7jFcXUyy+/rFtuuUXp6el65JFHvBdEwNcqbiU5W8WtpJIUHh6uyMhISdKECRP00EMP6cYbb+QNJxzjdrsr5c/j8SgpKUndunXzfn369Gk1bdpUbdq0kfT9ByzA18733uC6665TVFSUhg0bpoULF2rt2rVKT09XnTp1tHDhQh0/ftz3gwL/UXGdrbhu3nDDDRo7dqy6du0qqfyDvNvt1oEDB5SYmKhWrVo5OS7g970BG50bzrZtzZ49Wz169FCLFi10+vRp9ejRQ8XFxbrhhhvUpUsXrV+/Xn//+9+1YcMGJSQkOD0yqrmKzPbu3dt7W4l07of/5s2bKz8/XytWrPB+YAKccr7MVuQ1LS1N4eHhCgsL0+TJk/XZZ5+pQ4cODk+M6u7HrrNnmzhxot5++20tW7ZMTZs29fGEwLl+mNnvvvtOzZo1k8vl0qeffqrk5GRJUnZ2tmrWrMk/tMJxFZlNSUn50c9XTz75pObPn68lS5aoQYMGPp4QOJc/9waslDJURZf47rvv6sEHH9Rnn32m4uJi1axZU6tWrVK/fv20fft2TZ48WZmZmVqxYgWFFBz1w8ye3cpL5f+qVFJSohEjRig7O1urVq2ikIKjLpTZigLV7XZr6tSpeuaZZ7R69WoKKTjqp66zUvkTdsaNG6dZs2ZpwYIFFFJw1PkyW1paqsjISC1dulQrV670FlK2batZs2YUUnDUDzO7cuVK7+rpChkZGRo7dqxmzpypuXPnUkjBUSb0BuyyZoh9+/Zp9erVOn78uJKTk9WlSxdJ5U8qc7lc6tWrl4KDg+XxeBQcHKzJkyerrKxMhYWFCgkJqbQpJHC5XUxmf3iLicvlUmxsrD7//HO1bt3aibFRjV1KZkNDQxUaGqqNGzeqZcuWToyNauznZtbj8Wjz5s3av3+/PvvsMyUmJjo1Oqqpn8psSkqK90ERFQ+WqMBt0XDCxVxnz34Qj8fj0fr165Wdna01a9bwfhY+l52drffee0979+5Vr1699Lvf/U6Sf/cG3L5ngK1bt6p///6Ki4tTQUGBcnNzNW/ePN12223nPf/YsWOKjo727ZDAWX5uZr/99ltdccUVvh0SOMvPzWxBQYGioqJUUlKiQ4cOnbOhNOALl5pZt9utkydPKiIiwrcDo9rjvQFM80uus0VFRapdu7ZP5wW2bNmiPn36qE2bNrJtW0uWLNHbb7+toUOHnvd8f+kNuH3Pz+3du1f9+vXT4MGDtXTpUq1atUppaWl69tlnlZ+fX2lZ/pNPPqmJEydq3759Dk2M6u5SMvvEE0/om2++cWhiVHeXktkJEyYoJydHNWrUoJCCz11qZnNzcxUYGEghBZ+71PcGvJ+FU37pdZZCCr729ddfq2/fvrrnnnv08ccfa9GiRRoyZIiys7PPe74/9QaUUn6stLRUr776qjp27Kgnn3xSYWFhio+P1w033KADBw7IsqxKS5ndbreWL1+u4OBgh6ZGdfZLMhsSEuLQ1KjOfklmw8PDHZoa1dkvySy38sMJvJ+FabjOwjSlpaV66aWX1KdPH02cOFEuV/kuTR6PR//617/Uv39/Pfvss9q+fbv393g8Hr+5zlJK+bGgoCC1bt1aHTp0OOcDe5cuXWRZlo4ePept6St+nDx5stasWaM6deo4MjOqNzIL05BZmIbMwjRkFqYhszBNUFCQRo0apSFDhnhLpilTpmj+/PmqU6eOWrZsqWnTpmnq1KkqKyuTJD399NN+k1k2OvdzAwcOVM2aNSWVX/Qsy/Jupud2u73nffXVV96nk/jDfaGovsgsTENmYRoyC9OQWZiGzMI0LVu29D50JycnR5mZmfr444/Vp08fSVJKSop69+6tRx55RG3btpVlWYqKinJyZC9WSvmZiuayQsXFUCp/6khZWZlOnjwpt9utsLAwWZalxx9/XNdee62OHTvm63EBMgvjkFmYhszCNGQWpiGzMM0PM3u2pk2bavbs2erTp49s25Zt2woMDFRSUpJiY2O9t5/6y1NNKaX8yLZt2zRkyBDt2bPnR89xuVyqUaOG9+dPPfWUZs2apbVr19LOw+fILExDZmEaMgvTkFmYhszCNBfKbMUtpRVPL63YA23x4sWKiYlRWFiYT2e9KDb8Qk5Ojt2kSRPbsiy7U6dOdk5Ozo+eW1hYaCcmJtp9+/a1a9SoYW/atMmHkwLlyCxMQ2ZhGjIL05BZmIbMwjQ/J7O2bdv//ve/7QkTJtgRERH2li1bfDTlz8NKKT9QXFysN954Q8nJyVq3bp2Ki4s1cOBA7d27t9K5tm3r6NGj2r59u5YtW6YNGzaoQ4cODkyN6ozMwjRkFqYhszANmYVpyCxM83MyK0lZWVl6+OGH9f7772vVqlVKSkry8cQXx7Lt/6zvgmPKysq0YMECWZal22+/XUePHlVKSooCAgL00UcfqUmTJpV+z9SpU9W/f38lJiY6MDGqOzIL05BZmIbMwjRkFqYhszDNz82sx+PR8uXLlZCQoEaNGjk09U+jlPITpaWlCgoK8n6dl5en1NRUWZalBQsWqHHjxnK73dq0aZM6dux4zhMgACeQWZiGzMI0ZBamIbMwDZmFaS4ms2VlZdq8ebOSk5PPOddfUUr5Gfs/jxyVpEOHDqlPnz6yLEvz5s3TjBkz9NVXX2nhwoXejcsAp5FZmIbMwjRkFqYhszANmYVpfiqzmZmZ+uSTTxQVFeXwpD+NUspPVYQsLy9Pffv21datW+VyubR69Wp17NjR6fGASsgsTENmYRoyC9OQWZiGzMI0VSGzrD30UxWtZ3x8vJKSkhQREeFdNgr4IzIL05BZmIbMwjRkFqYhszBNVcgspZQPnTlzRrZtq6ioSFL5xmMXYtu20tPT9fe//10ZGRlq1aqVL8YEvMgsTENmYRoyC9OQWZiGzMI01S2zlFI+smPHDt1zzz3q1q2bevfurbVr1yogIOCCAbNtW4mJidq1a5eSk5N9OC1AZmEeMgvTkFmYhszCNGQWpqmOmWVPKR/Ytm2bunbtqqFDhyomJkZff/21/vnPf2rjxo1q3ry50+MBlZBZmIbMwjRkFqYhszANmYVpqmtmXU4PUNUdPXpUI0aM0H333afnn39eUvnu+Dt37tTq1avVvHnzc3bOB5xGZmEaMgvTkFmYhszCNGQWpqnOmeX2vcssJydHHo9HgwYN8h6rW7euYmNjtWPHDgcnA86PzMI0ZBamIbMwDZmFacgsTFOdM0spdZm1atVKjz32mDp16iRJKi0tlSRFRkaq4s7Jqth2wlxkFqYhszANmYVpyCxMQ2ZhmuqcWUqpy6xWrVq69dZbJZXvmh8UFCRJCg8P18mTJ73nTZ48WZ988okjMwJnI7MwDZmFacgsTENmYRoyC9NU58yyp9Sv7Ouvv9Yrr7yi3NxctWzZUmPGjFFsbKwkKSDg3A7Q7XZLkiZMmKApU6boyy+/9Pm8AJmFacgsTENmYRoyC9OQWZiGzH6PlVK/oqysLHXt2lXZ2dkKCQnRzJkzlZaWds45FYE6c+aMYmNj9fLLL+v555/Xpk2bjHx8I8xGZmEaMgvTkFmYhszCNGQWpiGzP2DjV7F//347KSnJfvjhh73HMjMz7bCwMHvlypWVzh81apRtWZYdERFhb9iwwZejArZtk1mYh8zCNGQWpiGzMA2ZhWnIbGXcvvcrWbp0qerUqaNx48ZJksrKytSoUSNdeeWVOnPmTKXz4+LiFBwcrHXr1ikxMdHX4wJkFsYhszANmYVpyCxMQ2ZhGjJbGbfv/UpuvPFGdenSRfXr15ckBQYGKjIyUqGhoTp8+HCl80ePHq2cnJwqGyz4PzIL05BZmIbMwjRkFqYhszANma2MlVK/kiZNmujpp5+WJNm2fc7jGs/eLX/evHlq1qyZOnbs6PMZgbORWZiGzMI0ZBamIbMwDZmFachsZayUugwsy1JZWZkkqWbNmoqMjJQkPfHEE7rzzjsVFRXl5HhAJWQWpiGzMA2ZhWnILExDZmEaMluOUuoyqWg8PR6PgoODNXXqVM2YMUMbNmxQ06ZNHZ4OqIzMwjRkFqYhszANmYVpyCxMQ2Yly7Zt2+khqrKUlBTt2LFDx44d05o1a6rF8juYjczCNGQWpiGzMA2ZhWnILExTnTPLnlKXiW3bKi4uVkFBgQ4dOqStW7dW6c3JYD4yC9OQWZiGzMI0ZBamIbMwDZllpdRlt2PHDtm2rVatWjk9CnBRyCxMQ2ZhGjIL05BZmIbMwjTVObOUUgAAAAAAAPA5NjoHAAAAAACAz1FKAQAAAAAAwOcopQAAAAAAAOBzlFIAAAAAAADwOUopAAAAAAAA+BylFAAAAAAAAHyOUgoAAAAAAAA+RykFAADgkHvuuUe33Xab02MAAAA4wuX0AAAAAFWRZVkX/PVJkyYpPT1dtm37aCIAAAD/QikFAABwGRw6dMj783nz5mnixInatWuX91h4eLjCw8OdGA0AAMAvcPseAADAZRAfH+/9LzIyUpZlnXMsPDy80u173bt315gxY5SWlqYrrrhCcXFxmjNnjk6ePKnhw4erVq1auuqqq/Tpp5+e82dlZWWpT58+Cg8PV1xcnO666y7l5+f7+DsGAAD4eSilAAAA/Mhbb72lmJgYbdiwQWPGjNGoUaM0aNAgdenSRZs3b1bv3r1111136dSpU5Kk48eP66abblJycrI2bdqkRYsW6fDhwxo8eLDD3wkAAMCFUUoBAAD4kbZt2+qJJ55QQkKCHn/8cYWEhCgmJkb333+/EhISNHHiRB07dkxbtmyRJM2aNUvJycmaOnWqWrRooeTkZP3tb3/TihUrtHv3boe/GwAAgB/HnlIAAAB+pE2bNt6fBwYGKjo6WklJSd5jcXFxkqQjR45IkjIzM7VixYrz7k+VnZ2tq6+++jJPDAAAcGkopQAAAPxIUFDQOV9blnXOsYqn+nk8HknSiRMndMstt+i5556r9Fp169a9jJMCAAD8MpRSAAAABmvfvr0+/PBDNW7cWC4Xb+0AAIA52FMKAADAYA8++KAKCgp05513auPGjcrOztbixYs1fPhwud1up8cDAAD4UZRSAAAABqtXr57Wrl0rt9ut3r17KykpSWlpaapdu7YCAnirBwAA/Jdl27bt9BAAAAAAAACoXvjnMwAAAAAAAPgcpRQAAAAAAAB8jlIKAAAAAAAAPkcpBQAAAAAAAJ+jlAIAAAAAAIDPUUoBAAAAAADA5yilAAAAAAAA4HOUUgAAAAAAAPA5SikAAAAAAAD4HKUUAAAAAAAAfI5SCgAAAAAAAD5HKQUAAAAAAACf+//gK2PYtGOb6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted dwell times for next hour:\n",
      "                  timestamp  predicted_dwell_time\n",
      "0 2024-12-22 12:00:00+00:00             13.946522\n",
      "1 2024-12-22 12:01:00+00:00             13.550901\n",
      "2 2024-12-22 12:02:00+00:00             13.044499\n",
      "3 2024-12-22 12:03:00+00:00             12.560619\n",
      "4 2024-12-22 12:04:00+00:00             12.044348\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DwellTimePredictor:\n",
    "    def __init__(self, save_dir='saved_models'):\n",
    "        self.save_dir = save_dir\n",
    "        self.trained_models = {}\n",
    "        self.seq_length = 30\n",
    "        \n",
    "    # [Previous methods remain the same until save_models]\n",
    "    \n",
    "    def save_models(self):\n",
    "        \"\"\"Save all trained models\"\"\"\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        for store_name, components in self.trained_models.items():\n",
    "            store_dir = os.path.join(self.save_dir, store_name.replace(' ', '_'))\n",
    "            os.makedirs(store_dir, exist_ok=True)\n",
    "            \n",
    "            # Add .keras extension for model saving\n",
    "            components['model'].save(os.path.join(store_dir, 'lstm_model.keras'))\n",
    "            joblib.dump(components['scaler'], os.path.join(store_dir, 'scaler.pkl'))\n",
    "            components['store_data'].to_pickle(os.path.join(store_dir, 'store_data.pkl'))\n",
    "            with open(os.path.join(store_dir, 'history.pkl'), 'wb') as f:\n",
    "                pickle.dump(components['history'].history, f)\n",
    "        \n",
    "        print(f\"Models saved to {self.save_dir}\")\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load all saved models\"\"\"\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            raise FileNotFoundError(f\"Directory {self.save_dir} not found\")\n",
    "        \n",
    "        store_dirs = [d for d in os.listdir(self.save_dir) \n",
    "                     if os.path.isdir(os.path.join(self.save_dir, d))]\n",
    "        \n",
    "        for store_dir in store_dirs:\n",
    "            store_path = os.path.join(self.save_dir, store_dir)\n",
    "            store_name = store_dir.replace('_', ' ')\n",
    "            \n",
    "            # Load model with .keras extension\n",
    "            model = load_model(os.path.join(store_path, 'lstm_model.keras'))\n",
    "            scaler = joblib.load(os.path.join(store_path, 'scaler.pkl'))\n",
    "            store_data = pd.read_pickle(os.path.join(store_path, 'store_data.pkl'))\n",
    "            \n",
    "            with open(os.path.join(store_path, 'history.pkl'), 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "            \n",
    "            class HistoryWrapper:\n",
    "                def __init__(self, history_dict):\n",
    "                    self.history = history_dict\n",
    "            \n",
    "            self.trained_models[store_name] = {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'store_data': store_data,\n",
    "                'history': HistoryWrapper(history)\n",
    "            }\n",
    "        \n",
    "        print(f\"Loaded models for stores: {list(self.trained_models.keys())}\")\n",
    "        \n",
    "    def create_sequences(self, data, seq_length):\n",
    "        \"\"\"Create sequences for LSTM\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            X.append(data[i:(i + seq_length)])\n",
    "            y.append(data[i + seq_length])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def prepare_data(self, df, store_name):\n",
    "        \"\"\"Prepare data for LSTM model\"\"\"\n",
    "        store_data = df[df['store'] == store_name].copy()\n",
    "        store_data['timestamp'] = pd.to_datetime(store_data['timestamp'])\n",
    "        \n",
    "        # Create features\n",
    "        store_data['hour'] = store_data['timestamp'].dt.hour\n",
    "        store_data['minute'] = store_data['timestamp'].dt.minute\n",
    "        store_data['day_of_week'] = store_data['timestamp'].dt.dayofweek\n",
    "        \n",
    "        # Cyclical features\n",
    "        store_data['hour_sin'] = np.sin(2 * np.pi * store_data['hour']/24)\n",
    "        store_data['hour_cos'] = np.cos(2 * np.pi * store_data['hour']/24)\n",
    "        store_data['minute_sin'] = np.sin(2 * np.pi * store_data['minute']/60)\n",
    "        store_data['minute_cos'] = np.cos(2 * np.pi * store_data['minute']/60)\n",
    "        \n",
    "        # One-hot encode day of week\n",
    "        dow_dummies = pd.get_dummies(store_data['day_of_week'], prefix='dow')\n",
    "        store_data = pd.concat([store_data, dow_dummies], axis=1)\n",
    "        \n",
    "        # Select features\n",
    "        feature_columns = ['dwell_time', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos'] + \\\n",
    "                         [col for col in store_data.columns if col.startswith('dow_')]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(store_data[feature_columns])\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = self.create_sequences(scaled_data, self.seq_length)\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        return (X_train, y_train), (X_test, y_test), scaler, store_data\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "        \"\"\"Build LSTM model\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(0.2),\n",
    "            LSTM(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_store_model(self, df, store_name):\n",
    "        \"\"\"Train model for a specific store\"\"\"\n",
    "        print(f\"\\nTraining model for {store_name}...\")\n",
    "        (X_train, y_train), (X_test, y_test), scaler, store_data = self.prepare_data(df, store_name)\n",
    "        \n",
    "        model = self.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        self.trained_models[store_name] = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'store_data': store_data,\n",
    "            'history': history\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def prepare_data(self, df, store_name):\n",
    "        \"\"\"Prepare data for LSTM model\"\"\"\n",
    "        store_data = df[df['store'] == store_name].copy()\n",
    "        \n",
    "        # Handle timezone conversion safely\n",
    "        store_data['timestamp'] = pd.to_datetime(store_data['timestamp'])\n",
    "        if store_data['timestamp'].dt.tz is None:\n",
    "            store_data['timestamp'] = store_data['timestamp'].dt.tz_localize('UTC')\n",
    "        else:\n",
    "            store_data['timestamp'] = store_data['timestamp'].dt.tz_convert('UTC')\n",
    "        \n",
    "        # Create features\n",
    "        store_data['hour'] = store_data['timestamp'].dt.hour\n",
    "        store_data['minute'] = store_data['timestamp'].dt.minute\n",
    "        store_data['day_of_week'] = store_data['timestamp'].dt.dayofweek\n",
    "        \n",
    "        # Cyclical features\n",
    "        store_data['hour_sin'] = np.sin(2 * np.pi * store_data['hour']/24)\n",
    "        store_data['hour_cos'] = np.cos(2 * np.pi * store_data['hour']/24)\n",
    "        store_data['minute_sin'] = np.sin(2 * np.pi * store_data['minute']/60)\n",
    "        store_data['minute_cos'] = np.cos(2 * np.pi * store_data['minute']/60)\n",
    "        \n",
    "        # Create fixed set of day-of-week dummies\n",
    "        for i in range(7):\n",
    "            store_data[f'dow_{i}'] = (store_data['day_of_week'] == i).astype(int)\n",
    "        \n",
    "        # Select features in fixed order\n",
    "        feature_columns = ['dwell_time', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos'] + \\\n",
    "                        [f'dow_{i}' for i in range(7)]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(store_data[feature_columns])\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = self.create_sequences(scaled_data, self.seq_length)\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        return (X_train, y_train), (X_test, y_test), scaler, store_data\n",
    "\n",
    "    def predict_next_hour(self, store_name, input_timestamp):\n",
    "        \"\"\"Predict dwell times for next hour\"\"\"\n",
    "        if store_name not in self.trained_models:\n",
    "            raise ValueError(f\"No trained model found for {store_name}\")\n",
    "            \n",
    "        # Standardize timestamp timezone handling\n",
    "        if isinstance(input_timestamp, str):\n",
    "            input_timestamp = pd.to_datetime(input_timestamp).tz_localize('UTC')\n",
    "        elif isinstance(input_timestamp, pd.Timestamp) and input_timestamp.tz is None:\n",
    "            input_timestamp = input_timestamp.tz_localize('UTC')\n",
    "        elif isinstance(input_timestamp, pd.Timestamp):\n",
    "            input_timestamp = input_timestamp.tz_convert('UTC')\n",
    "        \n",
    "        components = self.trained_models[store_name]\n",
    "        model = components['model']\n",
    "        scaler = components['scaler']\n",
    "        store_data = components['store_data'].copy()\n",
    "        \n",
    "        # Handle timezone conversion safely\n",
    "        if store_data['timestamp'].dt.tz is None:\n",
    "            store_data['timestamp'] = store_data['timestamp'].dt.tz_localize('UTC')\n",
    "        else:\n",
    "            store_data['timestamp'] = store_data['timestamp'].dt.tz_convert('UTC')\n",
    "        \n",
    "        # Generate future timestamps\n",
    "        future_timestamps = [input_timestamp + pd.Timedelta(minutes=i) for i in range(60)]\n",
    "        \n",
    "        # Create prediction DataFrame\n",
    "        pred_df = pd.DataFrame({'timestamp': future_timestamps})\n",
    "        pred_df['hour'] = pred_df['timestamp'].dt.hour\n",
    "        pred_df['minute'] = pred_df['timestamp'].dt.minute\n",
    "        pred_df['day_of_week'] = pred_df['timestamp'].dt.dayofweek\n",
    "        \n",
    "        # Create cyclical features\n",
    "        pred_df['hour_sin'] = np.sin(2 * np.pi * pred_df['hour']/24)\n",
    "        pred_df['hour_cos'] = np.cos(2 * np.pi * pred_df['hour']/24)\n",
    "        pred_df['minute_sin'] = np.sin(2 * np.pi * pred_df['minute']/60)\n",
    "        pred_df['minute_cos'] = np.cos(2 * np.pi * pred_df['minute']/60)\n",
    "        \n",
    "        # Create fixed set of day-of-week dummies\n",
    "        for i in range(7):\n",
    "            pred_df[f'dow_{i}'] = (pred_df['day_of_week'] == i).astype(int)\n",
    "        \n",
    "        # Get recent data for sequence\n",
    "        recent_data = store_data[store_data['timestamp'] < input_timestamp].tail(self.seq_length)\n",
    "        \n",
    "        if len(recent_data) < self.seq_length:\n",
    "            raise ValueError(\"Not enough historical data available\")\n",
    "        \n",
    "        # Prepare feature columns in same order as training\n",
    "        feature_columns = ['dwell_time', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos'] + \\\n",
    "                        [f'dow_{i}' for i in range(7)]\n",
    "        \n",
    "        # Create initial sequence\n",
    "        initial_sequence = scaler.transform(recent_data[feature_columns])\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = []\n",
    "        current_sequence = initial_sequence.copy()\n",
    "        \n",
    "        for i in range(60):\n",
    "            X = current_sequence.reshape(1, self.seq_length, len(feature_columns))\n",
    "            pred = model.predict(X, verbose=0)\n",
    "            predictions.append(pred[0][0])\n",
    "            \n",
    "            next_features = np.zeros(len(feature_columns))\n",
    "            next_features[0] = pred[0][0]\n",
    "            next_features[1:5] = [\n",
    "                pred_df.iloc[i]['hour_sin'],\n",
    "                pred_df.iloc[i]['hour_cos'],\n",
    "                pred_df.iloc[i]['minute_sin'],\n",
    "                pred_df.iloc[i]['minute_cos']\n",
    "            ]\n",
    "            for j in range(7):\n",
    "                next_features[5+j] = pred_df.iloc[i][f'dow_{j}']\n",
    "            \n",
    "            current_sequence = np.vstack([current_sequence[1:], next_features])\n",
    "        \n",
    "        # Scale back predictions\n",
    "        dummy = np.zeros((len(predictions), scaler.scale_.shape[0]))\n",
    "        dummy[:, 0] = predictions\n",
    "        predictions_unscaled = scaler.inverse_transform(dummy)[:, 0]\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            'timestamp': future_timestamps,\n",
    "            'predicted_dwell_time': predictions_unscaled\n",
    "        })\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def plot_predictions(self, predictions_df, store_name):\n",
    "        \"\"\"Plot predicted dwell times\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(predictions_df['timestamp'], predictions_df['predicted_dwell_time'], \n",
    "                 marker='o', linestyle='-', markersize=4)\n",
    "        plt.title(f\"Predicted Dwell Times for {store_name}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Predicted Dwell Time (minutes)\")\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize predictor\n",
    "    predictor = DwellTimePredictor()\n",
    "    \n",
    "    # If training new models:\n",
    "    df = pd.read_csv('synthetic_dwell_times.csv')\n",
    "    stores = ['Chicken Rice', 'Indian', 'Taiwanese']\n",
    "    \n",
    "    for store in stores:\n",
    "        predictor.train_store_model(df, store)\n",
    "    \n",
    "    # Save models\n",
    "    predictor.save_models()\n",
    "    \n",
    "    # Later, to load models and make predictions:\n",
    "    predictor.load_models()\n",
    "    \n",
    "    # Make prediction for specific time\n",
    "    timestamp = \"2024-12-22 12:00:00\"\n",
    "    store_name = \"Chicken Rice\"\n",
    "    \n",
    "    predictions = predictor.predict_next_hour(store_name, timestamp)\n",
    "    predictor.plot_predictions(predictions, store_name)\n",
    "    print(\"\\nPredicted dwell times for next hour:\")\n",
    "    print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
