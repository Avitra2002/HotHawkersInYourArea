{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def plot_predictions(results, store_name):\n",
    "    # Set the style to a default matplotlib style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create figure and axis for subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 12))\n",
    "    fig.suptitle(f'Prediction Analysis for {store_name}', fontsize=16)\n",
    "    \n",
    "    # 1. Time Series Plot with Confidence Intervals\n",
    "    axs[0, 0].plot(results['ds'], results['Actual'], label='Actual', marker='o', alpha=0.5)\n",
    "    axs[0, 0].plot(results['ds'], results['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "    axs[0, 0].fill_between(results['ds'], \n",
    "                          results['Lower_Bound'], \n",
    "                          results['Upper_Bound'], \n",
    "                          color='red', \n",
    "                          alpha=0.1)\n",
    "    axs[0, 0].set_title('Actual vs Predicted Values')\n",
    "    axs[0, 0].set_xlabel('Time')\n",
    "    axs[0, 0].set_ylabel('Dwell Time (minutes)')\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Scatter Plot\n",
    "    axs[0, 1].scatter(results['Actual'], results['Predicted'], alpha=0.5)\n",
    "    max_val = max(results['Actual'].max(), results['Predicted'].max())\n",
    "    axs[0, 1].plot([0, max_val], [0, max_val], 'r--', alpha=0.5)\n",
    "    axs[0, 1].set_title('Actual vs Predicted Scatter Plot')\n",
    "    axs[0, 1].set_xlabel('Actual Dwell Time')\n",
    "    axs[0, 1].set_ylabel('Predicted Dwell Time')\n",
    "    \n",
    "    # 3. Error Distribution\n",
    "    errors = results['Predicted'] - results['Actual']\n",
    "    axs[1, 0].hist(errors, bins=30, alpha=0.7)\n",
    "    axs[1, 0].set_title('Error Distribution')\n",
    "    axs[1, 0].set_xlabel('Prediction Error (minutes)')\n",
    "    axs[1, 0].set_ylabel('Count')\n",
    "    \n",
    "    # 4. Error vs Predicted Value\n",
    "    axs[1, 1].scatter(results['Predicted'], errors, alpha=0.5)\n",
    "    axs[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axs[1, 1].set_title('Error vs Predicted Value')\n",
    "    axs[1, 1].set_xlabel('Predicted Value')\n",
    "    axs[1, 1].set_ylabel('Error')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def prepare_and_predict(df, store_name, train_size=0.8):\n",
    "    # Filter data for specific store\n",
    "    store_data = df[df['store'] == store_name].copy()\n",
    "    \n",
    "    # Prepare data for Prophet\n",
    "    store_data = store_data.rename(columns={'timestamp': 'ds', 'dwell_time': 'y'})\n",
    "    \n",
    "    # Convert timestamp to datetime and remove timezone\n",
    "    store_data['ds'] = pd.to_datetime(store_data['ds']).dt.tz_localize(None)\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    store_data = store_data.sort_values('ds')\n",
    "    \n",
    "    # Add rolling statistics\n",
    "    window_sizes = [5, 10, 15]\n",
    "    for window in window_sizes:\n",
    "        store_data[f'rolling_mean_{window}'] = (\n",
    "            store_data['y']\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "            .fillna(method='bfill')\n",
    "            .fillna(method='ffill')\n",
    "        )\n",
    "    \n",
    "    # Split the data\n",
    "    train_idx = int(len(store_data) * train_size)\n",
    "    train_data = store_data[:train_idx]\n",
    "    test_data = store_data[train_idx:]\n",
    "    \n",
    "    print(f\"\\nStore: {store_name}\")\n",
    "    print(f\"Training data size: {len(train_data)}\")\n",
    "    print(f\"Testing data size: {len(test_data)}\")\n",
    "    \n",
    "    # Create and train the model with optimized parameters\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.5,\n",
    "        daily_seasonality=20,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False,\n",
    "        seasonality_prior_scale=15,\n",
    "        changepoint_range=0.9,\n",
    "        interval_width=0.95\n",
    "    )\n",
    "    \n",
    "    # Add custom seasonalities\n",
    "    model.add_seasonality(\n",
    "        name='lunch_peak',\n",
    "        period=1,\n",
    "        fourier_order=8,\n",
    "        condition_name='is_lunch'\n",
    "    )\n",
    "    \n",
    "    model.add_seasonality(\n",
    "        name='dinner_peak',\n",
    "        period=1,\n",
    "        fourier_order=8,\n",
    "        condition_name='is_dinner'\n",
    "    )\n",
    "    \n",
    "    model.add_seasonality(\n",
    "        name='morning_peak',\n",
    "        period=1,\n",
    "        fourier_order=5,\n",
    "        condition_name='is_morning'\n",
    "    )\n",
    "    \n",
    "    model.add_seasonality(\n",
    "        name='afternoon_peak',\n",
    "        period=1,\n",
    "        fourier_order=5,\n",
    "        condition_name='is_afternoon'\n",
    "    )\n",
    "    \n",
    "    # Add time-based conditions\n",
    "    train_data['is_lunch'] = train_data['ds'].apply(lambda x: 1 if 11 <= x.hour <= 14 else 0)\n",
    "    train_data['is_dinner'] = train_data['ds'].apply(lambda x: 1 if 17 <= x.hour <= 19 else 0)\n",
    "    train_data['is_morning'] = train_data['ds'].apply(lambda x: 1 if 8 <= x.hour <= 10 else 0)\n",
    "    train_data['is_afternoon'] = train_data['ds'].apply(lambda x: 1 if 14 <= x.hour <= 16 else 0)\n",
    "    train_data['hour'] = train_data['ds'].dt.hour\n",
    "    \n",
    "    # Add regressors\n",
    "    model.add_regressor('hour')\n",
    "    for window in window_sizes:\n",
    "        model.add_regressor(f'rolling_mean_{window}')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(train_data)\n",
    "    \n",
    "    # Create future dataframe for test period\n",
    "    future = model.make_future_dataframe(\n",
    "        periods=len(test_data),\n",
    "        freq='min'\n",
    "    )\n",
    "    \n",
    "    # Add all features to future dataframe\n",
    "    future['is_lunch'] = future['ds'].apply(lambda x: 1 if 11 <= x.hour <= 14 else 0)\n",
    "    future['is_dinner'] = future['ds'].apply(lambda x: 1 if 17 <= x.hour <= 19 else 0)\n",
    "    future['is_morning'] = future['ds'].apply(lambda x: 1 if 8 <= x.hour <= 10 else 0)\n",
    "    future['is_afternoon'] = future['ds'].apply(lambda x: 1 if 14 <= x.hour <= 16 else 0)\n",
    "    future['hour'] = future['ds'].dt.hour\n",
    "    \n",
    "    # Add rolling statistics to future dataframe\n",
    "    for window in window_sizes:\n",
    "        future[f'rolling_mean_{window}'] = train_data[f'rolling_mean_{window}'].mean()\n",
    "    \n",
    "    # Make predictions\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Get predictions for test period\n",
    "    test_predictions = forecast.tail(len(test_data))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(test_data['y'], test_predictions['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(test_data['y'], test_predictions['yhat']))\n",
    "    \n",
    "    print(f\"\\nMetrics for {store_name}:\")\n",
    "    print(f\"MAE: {mae:.2f} minutes\")\n",
    "    print(f\"RMSE: {rmse:.2f} minutes\")\n",
    "    \n",
    "    # Return predictions and actual values\n",
    "    results = pd.DataFrame({\n",
    "        'ds': test_data['ds'].values,\n",
    "        'Actual': test_data['y'].values,\n",
    "        'Predicted': test_predictions['yhat'].values,\n",
    "        'Lower_Bound': test_predictions['yhat_lower'].values,\n",
    "        'Upper_Bound': test_predictions['yhat_upper'].values\n",
    "    })\n",
    "    \n",
    "    # Plot the predictions\n",
    "    plot_predictions(results, store_name)\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "def main():\n",
    "    # Read the data\n",
    "    df = pd.read_csv('output.csv')\n",
    "    \n",
    "    # List of stores\n",
    "    stores = ['Chicken Rice', 'Indian', 'Taiwanese']\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    store_results = {}\n",
    "    \n",
    "    # Process each store\n",
    "    for store in stores:\n",
    "        model, results = prepare_and_predict(df, store)\n",
    "        store_results[store] = {\n",
    "            'model': model,\n",
    "            'predictions': results\n",
    "        }\n",
    "        \n",
    "        # Print sample of predictions vs actual\n",
    "        print(f\"\\nSample predictions for {store}:\")\n",
    "        print(results.head())\n",
    "    \n",
    "    return store_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
